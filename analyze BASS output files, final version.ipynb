{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import poisson\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "from cycler import cycler\n",
    "from copy import deepcopy\n",
    "from hmmlearn import hmm\n",
    "from sklearn import mixture\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM_model:\n",
    "    def __init__(self,numclasses):\n",
    "        self.numclasses = numclasses\n",
    "        \n",
    "    def E_step(self,datasets):\n",
    "        N = datasets.shape[1]\n",
    "        numsets = datasets.shape[0]\n",
    "        gamma_ = np.zeros((numsets,N,self.numclasses))\n",
    "        for k in range(self.numclasses):\n",
    "            gamma_[:,:,k] = 1e-20 + self.weights_[:,k][:,np.newaxis]*stats.multivariate_normal.pdf(datasets,mean = self.means_[k],cov = self.covars_[k])\n",
    "        gamma_ = gamma_/np.sum(gamma_,axis=2)[:,:,np.newaxis]\n",
    "        return gamma_\n",
    "    \n",
    "    def M_step(self,datasets,gamma_):\n",
    "        for k in range(self.numclasses):\n",
    "            Nk = np.sum(gamma_[:,:,k])\n",
    "            self.means_[k] = np.sum(np.sum(gamma_[:,:,k][:,:,None]*datasets,axis=1),axis=0)/Nk\n",
    "            outerprod = (datasets - self.means_[k])[:,:,:,None]*(datasets - self.means_[k])[:,:,None,:]\n",
    "            self.covars_[k] = np.sum(np.sum(gamma_[:,:,k][:,:,None,None]*outerprod,axis=1),axis=0)/Nk\n",
    "            self.weights_ = np.sum(gamma_,axis=1)/self.N\n",
    "            \n",
    "    def LL(self,datasets):\n",
    "        N = datasets.shape[1]\n",
    "        numsets = datasets.shape[0]\n",
    "        temp = np.zeros((numsets,N))\n",
    "        for k in range(self.numclasses):\n",
    "            temp += self.weights_[:,k][:,None]*stats.multivariate_normal.pdf(datasets,mean = self.means_[k],cov = self.covars_[k])\n",
    "        LL = np.mean(np.log(temp + 1e-80))\n",
    "        return -LL\n",
    "        \n",
    "    def solve(self,datasets):\n",
    "        self.numsets= len(datasets)\n",
    "        self.dim = datasets.shape[2]\n",
    "        self.N = datasets.shape[1]\n",
    "        self.means_ = np.zeros((self.numclasses,self.dim))\n",
    "        self.covars_ = np.zeros((self.numclasses, self.dim,self.dim))\n",
    "        self.weights_ = np.zeros((self.numsets,self.numclasses))\n",
    "        \n",
    "        datasets_flat = np.reshape(datasets,(-1,datasets.shape[2]))\n",
    "        covar = np.cov(datasets_flat, rowvar = False)\n",
    "        mean = np.mean(datasets_flat, axis = 0)\n",
    "        \n",
    "        numinits = 20\n",
    "        means_init = np.zeros((numinits,self.numclasses,self.dim))\n",
    "        covars_init = np.zeros((numinits,self.numclasses,self.dim,self.dim))\n",
    "        weights_init = np.zeros((numinits,self.numsets,self.numclasses))\n",
    "        LL_init = np.zeros(numinits)\n",
    "        for init_ in range(numinits):\n",
    "            for i in range(self.numclasses):\n",
    "                means_init[init_][i] = np.random.multivariate_normal(mean,covar)\n",
    "                covars_init[init_][i] = deepcopy(covar)\n",
    "\n",
    "            for j in range(self.numsets):\n",
    "                weights_init[init_][j] = np.random.dirichlet(5*np.ones(self.numclasses))\n",
    "            self.means_ = means_init[init_]\n",
    "            self.covars_ = covars_init[init_]\n",
    "            self.weights_ = weights_init[init_]\n",
    "            LL_init[init_] = self.LL(datasets)\n",
    "        best = np.argmin(LL_init)\n",
    "        self.means_ = means_init[best]\n",
    "        self.covars_ = covars_init[best]\n",
    "        self.weights_ = weights_init[best]\n",
    "            \n",
    "        LL_curr = self.LL(datasets)\n",
    "        LL_prev = 0\n",
    "        print(\"Initial negative log-likelihood per sample = %.4f\" %LL_curr)\n",
    "        num = 0\n",
    "        while np.abs(LL_curr - LL_prev) > 1e-4:\n",
    "            gamma_= self.E_step(datasets)\n",
    "            self.M_step(datasets,gamma_)\n",
    "            LL_prev = LL_curr\n",
    "            LL_curr = self.LL(datasets)\n",
    "            num += 1\n",
    "            #print(LL_curr)\n",
    "        print(\"Final negative log-likelihood per sample = %.4f\" %LL_curr)\n",
    "        print(\"Number of iterations = %d\" %num)\n",
    "        \n",
    "    def _compute_posterior(self,y,set_index):\n",
    "        post = np.zeros(self.numclasses)\n",
    "        for k in range(self.numclasses):\n",
    "            post[k] = self.weights_[set_index][k]*self._compute_likelihood(y,k)\n",
    "        return post/np.sum(post)\n",
    "        \n",
    "    def _compute_likelihood(self,y,s):\n",
    "        return stats.multivariate_normal.pdf(y,mean = self.means_[s],cov = self.covars_[s])\n",
    "    \n",
    "    def _compute_log_likelihood(self,data):\n",
    "        Y = np.zeros((len(data),self.numclasses))\n",
    "        for k in range(self.numclasses):\n",
    "            Y[:,k] = np.log(stats.multivariate_normal.pdf(data,mean = self.means_[k],cov = self.covars_[k]) + 1e-80)\n",
    "        return Y\n",
    "    def score(self,dataset,set_index):\n",
    "        temp = np.zeros(len(dataset))\n",
    "        for k in range(self.numclasses):\n",
    "            temp += self.weights_[set_index,k]*stats.multivariate_normal.pdf(dataset,mean = self.means_[k],cov = self.covars_[k])\n",
    "        LL = np.sum(np.log(temp + 1e-80))\n",
    "        return LL\n",
    "        \n",
    "    def _generate_sample_from_state(self,s):\n",
    "        return np.random.multivariate_normal(self.means_[s],self.covars_[s])\n",
    "    \n",
    "    def _read_params(self,means_,covars_,weights_):\n",
    "        self.numclasses = means_.shape[0]\n",
    "        self.means_ = means_\n",
    "        self.covars_ = covars_\n",
    "        self.weights_ = weights_\n",
    "        \n",
    "    def _save_params(self,filename):\n",
    "        np.save(filename + \"_means\",self.means_)\n",
    "        np.save(filename + \"_covars\",self.covars_)\n",
    "        np.save(filename + \"_weights\",self.weights_)\n",
    "        \n",
    "def compute_transmat(Y):\n",
    "    #Initialize transition matrices\n",
    "    numclasses = Y.shape[1]\n",
    "    transmat_ = np.zeros((numclasses,numclasses))\n",
    "    stationary_probs_ = np.random.dirichlet(5*np.ones(numclasses))\n",
    "    for k in range(numclasses):\n",
    "        transmat_[k] = np.random.dirichlet(5*np.ones(numclasses))\n",
    "    for k in range(numclasses):\n",
    "        for iter_ in range(50):\n",
    "            stationary_probs_ = np.einsum('i,ij', stationary_probs_, transmat_)\n",
    "            \n",
    "    numiter = 100\n",
    "    LLs = np.zeros(numiter)\n",
    "    \n",
    "    #compute alphas\n",
    "    for iter_ in range(numiter):\n",
    "        N = Y.shape[0]\n",
    "        alphas = np.zeros((N,numclasses))\n",
    "        norms = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            if i == 0:\n",
    "                alphas[i] = stationary_probs_*Y[i] \n",
    "            else:  \n",
    "                alphas[i] = np.einsum('i,ij',alphas[i-1],transmat_)*Y[i]\n",
    "            norms[i] = np.sum(alphas[i])\n",
    "            alphas[i] /= norms[i]\n",
    "\n",
    "        \n",
    "        LLs[iter_] = -np.sum(np.log(norms + 1e-20))/N\n",
    "        #print(iter_,LLs[iter_])\n",
    "        if iter_ > 5 and np.abs(LLs[iter_] - LLs[iter_-1]) < 1e-4:\n",
    "            break\n",
    "        #compute betas\n",
    "        betas = np.zeros((N,numclasses))\n",
    "        for i in range(N-1,-1,-1):\n",
    "            if i == N-1:\n",
    "                betas[i] = 1.0\n",
    "            else:  \n",
    "                betas[i] = np.einsum('j,ij,j', betas[i+1], transmat_,Y[i+1])\n",
    "            betas[i] /= np.sum(betas[i])\n",
    "\n",
    "        #compute states\n",
    "        gamma_ = np.zeros((N,numclasses))\n",
    "        for i in range(N):\n",
    "            gamma_[i] = alphas[i]*betas[i]/np.sum(alphas[i]*betas[i])\n",
    "\n",
    "        #compute transitions:\n",
    "        xi_ = np.zeros((N,numclasses,numclasses))\n",
    "        for j in range(numclasses):\n",
    "            for k in range(numclasses):\n",
    "                xi_[1:,j,k] = alphas[:-1,j]*transmat_[j,k]*Y[1:,k]*betas[1:,k]\n",
    "        xi_ /= np.sum(xi_,axis=(1,2))[:,None,None]\n",
    "\n",
    "        #update transmat_\n",
    "        for k in range(numclasses):\n",
    "            transmat_[:,k] = np.sum(xi_[1:,:,k],axis=0)/np.sum(gamma_[:-1],axis=0)\n",
    "        stationary_probs_ = gamma_[0]\n",
    "        for k in range(numclasses):\n",
    "            transmat_[k] /= np.sum(transmat_[k])\n",
    "            \n",
    "        for k in range(numclasses):\n",
    "            for iter_ in range(50):\n",
    "                stationary_probs_ = np.einsum('i,ij', stationary_probs_, transmat_)\n",
    "    \n",
    "    return transmat_,stationary_probs_\n",
    "\n",
    "def test_for_markovianity(Y,w_dict,eps,p_d,transmat_, stationary_probs_):\n",
    "    lengths = [len(w) for w in w_dict]\n",
    "    lmean = np.mean(lengths)\n",
    "    mlnPs = np.zeros(len(w_dict))\n",
    "    emps =  np.zeros(len(w_dict))\n",
    "    exps =  np.zeros(len(w_dict))\n",
    "    for i,w in enumerate(w_dict):\n",
    "        seqs,probs = get_mutated_sequences_prob(list(w),eps,p_d)\n",
    "        emp = 0\n",
    "        exp = 0\n",
    "        for j,seq in enumerate(seqs):\n",
    "            seq_arr = np.array(seq,dtype = int)\n",
    "            #print(w,seq_arr,probs[i])\n",
    "            emp += calculate_empirical_frequency_hmm(seq_arr,Y,transmat_, stationary_probs_)*probs[j]\n",
    "            exp += calculate_expected_frequency_hmm(seq_arr,transmat_, stationary_probs_)*probs[j]\n",
    "\n",
    "        q1 = 1 + (1.0/exp + 1.0/(1-exp) - 1)/(6.0*len(Y)) #correction to LR test\n",
    "        ll = 2*len(Y)*(emp*np.log(emp/exp) + (1-emp)*np.log((1-emp)/(1-exp)))/q1\n",
    "        mlnP = -np.log10(stats.chi2.sf(ll,1))\n",
    "        mlnPs[i] = mlnP\n",
    "        emps[i] = emp\n",
    "        exps[i] = exp\n",
    "        #print(\"%04d %04d %2.2f\"%(emp*len(Y),exp*len(Y),mlnP),w)\n",
    "    sorted_ = np.argsort(-mlnPs)\n",
    "    for w in sorted_:\n",
    "        if emps[w] > exps[w] and 10**(-mlnPs[w]) < 1:#used to be 1e-3 not 1\n",
    "            print(\"%04d %04d %2.2f\"%(emps[w]*len(Y),exps[w]*len(Y),mlnPs[w]),w_dict[w])\n",
    "    return mlnPs,emps,exps\n",
    "\n",
    "def print_dict(Y,w_dict,P_w):\n",
    "    sorted_ = np.argsort(-P_w)\n",
    "    lengths = [len(w) for w in w_dict]\n",
    "    lmean = np.mean(lengths)\n",
    "    for i in sorted_[:]:\n",
    "        print(\"%.4f %d\"%(P_w[i],P_w[i]*len(Y)/lmean),w_dict[i])\n",
    "\n",
    "#Combine two dictionaries:\n",
    "def combine_dicts(w_dict1, w_dict2, params, model):\n",
    "    w_dict = w_dict1 + w_dict2\n",
    "    eps = params[0]\n",
    "    params[0] = 0\n",
    "    P_w = []\n",
    "    w_dict = remove_duplicates_w_dict(P_w,w_dict,params,model)\n",
    "    return w_dict\n",
    "    \n",
    "def compare_datasets(Y1, lengths_Y1, Y2, lengths_Y2,w_dict1, w_dict2, params,model):\n",
    "    w_dict = combine_dicts(w_dict1,w_dict2,params,model)\n",
    "    P_w1 = get_P_w(Y1,lengths_Y1,w_dict,params)\n",
    "    P_w2 = get_P_w(Y2,lengths_Y2,w_dict,params)\n",
    "    lengths = [len(w) for w in w_dict]\n",
    "    lmean = np.sum(P_w2*lengths)\n",
    "    N_av2 = len(Y2)/lmean\n",
    "    scores = np.zeros(len(w_dict))\n",
    "    print(len(w_dict), len(w_dict1), len(w_dict2))\n",
    "    emps = np.zeros(len(w_dict))\n",
    "    exps = np.zeros(len(w_dict))\n",
    "    for w in range(len(w_dict)):\n",
    "        f_calc = P_w2[w]\n",
    "        f_exp =  P_w1[w]\n",
    "        q1 = 1 + (1.0/f_exp + 1.0/(1-f_exp) - 1)/(6.0*N_av2) #correction to LR test\n",
    "        m2lnLR = 2*N_av2*(f_calc*np.log(f_calc/f_exp) + (1-f_calc)*np.log((1-f_calc)/(1-f_exp)))\n",
    "        scores[w] = -np.log10(stats.chi2.sf(m2lnLR,1))\n",
    "        emps[w] = f_calc*N_av2\n",
    "        exps[w] = f_exp*N_av2\n",
    "    sorted_ = np.argsort(-scores)\n",
    "    for w in sorted_:\n",
    "        if N_av2*P_w2[w] > 10 and len(w_dict[w]) > 1 and 10**(-scores[w]) < 1 and N_av2*P_w1[w] > 10:\n",
    "            print( \"%04d %04d %.2f\" %(N_av2*P_w1[w],N_av2*P_w2[w], scores[w]),w_dict[w])\n",
    "    return scores,emps,exps\n",
    "\n",
    "            \n",
    "#def compare_datasets_frequencies()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.math cimport log\n",
    "from libc.math cimport exp\n",
    "from libc.math cimport ceil\n",
    "from libc.math cimport pow\n",
    "from libc.math cimport sqrt\n",
    "from libc.math cimport cos\n",
    "from libc.math cimport sin\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "from scipy.misc import comb\n",
    "from scipy.stats import poisson\n",
    "import cython\n",
    "import sys\n",
    "from scipy.stats import norm\n",
    "import editdistance\n",
    "\n",
    "# cython: profile=True\n",
    "\n",
    "#P_ygs is the likelihood function. Outputs the probability of observing y given s.\n",
    "@cython.cdivision(True)\n",
    "cpdef double P_ygs(double [:] y, int s, int numclasses, double std):\n",
    "    cdef int dim = 2\n",
    "    cdef double means0 = 0\n",
    "    cdef double means1 = 0\n",
    "    cdef double PI = 3.1415926\n",
    "    if s < numclasses - 1 and numclasses > 1:\n",
    "        means0 =  cos(PI*2*s/(numclasses-1))\n",
    "        means1 =  sin(PI*2*s/(numclasses-1))\n",
    "    cdef double prob1 =  exp(-(y[0] - means0)*(y[0] - means0)/(2*std*std))/sqrt(2*PI*std*std)\n",
    "    cdef double prob2 =  exp(-(y[1] - means1)*(y[1] - means1)/(2*std*std))/sqrt(2*PI*std*std)\n",
    "    return prob1*prob2\n",
    "\n",
    "@cython.cdivision(True)\n",
    "cpdef double [:] sample_y(int s, int numclasses, double std):\n",
    "    cdef int dim = 2\n",
    "    cdef double means0 = 0\n",
    "    cdef double means1 = 0\n",
    "    cdef double PI = 3.1415926\n",
    "    if s < numclasses - 1:\n",
    "        means0 =  cos(PI*2*s/(numclasses-1))\n",
    "        means1 =  sin(PI*2*s/(numclasses-1))\n",
    "        \n",
    "    cdef double [:] Y = np.zeros(dim,dtype = float)\n",
    "    Y[0] = means0 + std*np.random.randn()\n",
    "    Y[1] = means1 + std*np.random.randn()\n",
    "    return Y\n",
    "    \n",
    "    \n",
    "cpdef double P_YgS_func_noeps(double [:,:] Y,  np.int_t[:] S):\n",
    "    cdef int lenY = Y.shape[0]\n",
    "    cdef int lenS = S.shape[0]\n",
    "    cdef int i\n",
    "    cdef double prod = 1\n",
    "    if lenY != lenS:\n",
    "        return 0\n",
    "    else:\n",
    "        for i in range(lenS):\n",
    "            prod = prod*Y[i,S[i]]\n",
    "        return prod\n",
    "    \n",
    "    \n",
    "@cython.cdivision(True)\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "@cython.wraparound(False)  # turn off negative index wrapping for entire function\n",
    "cpdef double P_YgS_func(double[:,:] Y, np.int_t [:] S, double [:] params, double[:,:] P_memo):\n",
    "    cdef int i,j\n",
    "    cdef double eps,p_d,p_ins\n",
    "    eps = params[0]\n",
    "    p_d = params[1]\n",
    "    p_ins = params[2]\n",
    "    cdef int Ly = Y.shape[0]\n",
    "    cdef int Ls = S.shape[0]\n",
    "    cdef double P = 0\n",
    "    if Ly == 0:\n",
    "        return pow(eps*p_d,Ls)\n",
    "    elif Ls == 0 or Ly < 0:\n",
    "        return 0.0\n",
    "    elif Ly > 2*Ls:\n",
    "        return 0.0       \n",
    "    elif P_memo[Ly-1,Ls-1] > -1:\n",
    "        return P_memo[Ly-1,Ls-1]\n",
    "    else:\n",
    "        for i in range(min(3,Ly+1)):\n",
    "#        for i in range(Ly+1):\n",
    "            if i == 0 and eps*p_d > 1e-3:\n",
    "                P += eps*p_d*P_YgS_func(Y[:],S[:Ls-1],params,P_memo)\n",
    "            elif i == 1:\n",
    "                P += (1-eps)*P_YgS_func(Y[:Ly-1],S[:Ls-1],params,P_memo)*Y[Ly-1,S[Ls-1]]\n",
    "            elif i == 2 and eps*(1-p_d) > 1e-3: \n",
    "                P += eps*(1-p_d)*P_YgS_func(Y[:Ly-2],S[:Ls-1],params,P_memo)*Y[Ly-1,S[Ls-1]]*Y[Ly-2,S[Ls-1]]\n",
    "#             elif i > 2 and eps*(1-p_d)*pow(p_ins,i-2) > 1e-3:\n",
    "#                 prod = pow(p_ins,i-2)\n",
    "#                 for j in range(i):\n",
    "#                     prod *= P_ygs(Y[Ly-j-1],S[Ls-1])\n",
    "#                 P += eps*prod*P_YgS_func(Y[:Ly-i],S[:Ls-1],params,P_memo)*(1-p_d)*(1-p_ins)\n",
    "    P_memo[Ly-1,Ls-1] = P\n",
    "    return P\n",
    "\n",
    "@cython.cdivision(True)\n",
    "cpdef double P_YgS(double [:,:] Y,  np.int_t[:] S, double [:] params):\n",
    "    cdef int lenY = Y.shape[0]\n",
    "    cdef int lenS = S.shape[0]\n",
    "    if params[0] < 1e-3 or lenS == 1:\n",
    "        return P_YgS_func_noeps(Y,S)\n",
    "    cdef double [:,::1] P_memo = -5*np.ones((lenY,lenS),dtype = float)\n",
    "    return P_YgS_func(Y,S,params,P_memo)/(1.0 - pow(params[0]*params[1],lenS)) #divide by the possibility of S -> null.\n",
    "\n",
    "def get_lmax(w_dict,params):\n",
    "    eps = params[0]\n",
    "    p_d = params[1]\n",
    "    p_ins = params[2]\n",
    "    lengths = [len(w) for w in w_dict]\n",
    "    return 30#int(ceil(np.max(lengths)*2))\n",
    "\n",
    "def get_lmin_and_max(w,params):\n",
    "    l = len(w)\n",
    "    eps = params[0]\n",
    "    p_d = params[1]\n",
    "    p_ins = params[2]\n",
    "    lmin = 0\n",
    "    lmax = 2*l\n",
    "    for k in range(l):\n",
    "        if comb(l,k)*pow(eps*p_d,k)*pow(1-eps,l-k) < 5e-3:\n",
    "            lmin = l - k - 1\n",
    "            break\n",
    "    for k in range(l + 1):\n",
    "        if comb(l,k)*pow(eps*(1-p_d),k)*pow(1-eps,l-k) < 5e-3:\n",
    "            lmax = l + k\n",
    "            break\n",
    "    return lmin,lmax\n",
    "    \n",
    "\n",
    "def append_mseq(sym,seqs):\n",
    "    mseqs = []\n",
    "    for i in range(len(seqs)):\n",
    "        mseqs += [[sym] + seqs[i]]\n",
    "    return mseqs\n",
    "\n",
    "def generate_mutated_sequences(seq,eps,p_d):\n",
    "    mseqs = []\n",
    "    probs_mseqs = []\n",
    "    if len(seq) == 1:\n",
    "        return [[seq[0]],[],[seq[0],seq[0]]],[1-eps,eps*p_d,eps*(1-p_d)]\n",
    "    \n",
    "    seqs,probs = generate_mutated_sequences(seq[1:],eps,p_d)\n",
    "       \n",
    "    mseqs += append_mseq(seq[0],seqs)\n",
    "    probs_mseqs += [p*(1-eps) for p in probs]\n",
    "    \n",
    "    mseqs += seqs\n",
    "    probs_mseqs += [p*eps*p_d for p in probs]\n",
    "    \n",
    "    seqs_dup = append_mseq(seq[0],seqs)\n",
    "    seqs_dup = append_mseq(seq[0],seqs_dup)\n",
    "    mseqs += seqs_dup\n",
    "    probs_mseqs += [p*eps*(1-p_d) for p in probs]\n",
    "    \n",
    "    dups = []\n",
    "    for i in range(len(mseqs)):\n",
    "        for j in range(i+1,len(mseqs)):\n",
    "            if np.array_equal(mseqs[i],mseqs[j]):\n",
    "                dups += [j]\n",
    "                probs_mseqs[i] += probs_mseqs[j]\n",
    "                \n",
    "    dups = np.array(dups)\n",
    "    dups = np.unique(dups)                \n",
    "    #print(dups)\n",
    "    for j in range(len(dups)):\n",
    "        del mseqs[dups[j]]\n",
    "        del probs_mseqs[dups[j]]\n",
    "        dups -= 1\n",
    "        \n",
    "    seqs_out = []\n",
    "    probs_out = []\n",
    "    for i in range(len(mseqs)):\n",
    "        if probs_mseqs[i] > 5e-4:\n",
    "            seqs_out += [mseqs[i]]\n",
    "            probs_out += [probs_mseqs[i]]\n",
    "            \n",
    "    return seqs_out,probs_out\n",
    "\n",
    "def get_mutated_sequences_prob(seq,eps,p_d):\n",
    "    if len(seq) == 1:\n",
    "        return [seq],[1.0]\n",
    "    else:\n",
    "        seqs,probs = generate_mutated_sequences(seq,eps,p_d)\n",
    "        empty_prob = 0\n",
    "        for i in range(len(seqs)):\n",
    "            if len(seqs[i]) == 0:\n",
    "                empty_prob = probs[i]\n",
    "                del seqs[i]\n",
    "                del probs[i]\n",
    "                break\n",
    "            \n",
    "        for i in range(len(seqs)):\n",
    "            probs[i] /= (1-empty_prob)\n",
    "        return seqs,probs\n",
    "\n",
    "\n",
    "@cython.cdivision(True)\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def get_W_ils(w_dict, double[:,:] Y, np.int_t[:] lengths_Y, double [:] params):\n",
    "    cdef int L = Y.shape[0]\n",
    "    cdef int D = len(w_dict)\n",
    "    cdef int K = lengths_Y.shape[0]\n",
    "    cdef int lmax = get_lmax(w_dict,params)\n",
    "    \n",
    "    Q_gw = np.zeros((L,lmax), dtype=float) \n",
    "    cdef double[:,:] Q_gw_view = Q_gw\n",
    "    \n",
    "    cdef np.int_t[:] w_dict_view\n",
    "    \n",
    "    cdef int i,w,k,j,lmin,l,kk,mlen,wtild\n",
    "    cdef double [:] Pmtilds\n",
    "    cdef np.int_t [:] seq_mtild\n",
    "    cdef double w_thr = params[4]\n",
    "    cdef double w_thr_l = 0\n",
    "    W_ils = []\n",
    "    \n",
    "    for w in range(D):\n",
    "        W_ils += [[]]\n",
    "        \n",
    "        w_dict_view = w_dict[w]\n",
    "        lmin,lmax = get_lmin_and_max(w_dict[w],params)\n",
    "        lw = w_dict[w].shape[0]\n",
    "        seqs,probs = get_mutated_sequences_prob(w_dict_view, params[0],params[1])\n",
    "        Pmtilds = np.array(probs,dtype = float)\n",
    "        mlen = Pmtilds.shape[0]\n",
    "        \n",
    "        Q_gw_view = np.zeros(Q_gw.shape, dtype=float) \n",
    "        for wtild in range(mlen):\n",
    "            seq_mtild = np.array(seqs[wtild],dtype = int)\n",
    "            l = seq_mtild.shape[0]-1\n",
    "            kk = 0\n",
    "            for k in range(K):\n",
    "                L = lengths_Y[k]\n",
    "                for i in range(l,L):\n",
    "                    Q_gw_view[i+kk,l] += P_YgS_func_noeps(Y[i+kk-l:i+kk+1],seq_mtild)*Pmtilds[wtild]\n",
    "                kk += L\n",
    "        \n",
    "        L = Y.shape[0]\n",
    "        for i in range(L):\n",
    "            for l in range(min(i+1,lmax)):\n",
    "                w_thr_l = pow(w_thr,l+1)\n",
    "                if Q_gw_view[i,l] > w_thr_l:\n",
    "                    W_ils[w] += [[i,l,Q_gw_view[i,l]]] \n",
    "    return W_ils\n",
    "\n",
    "def get_Q_gw_from_W_il(W_ils_w,Y,w_dict,params):\n",
    "    L = Y.shape[0]\n",
    "    lmax = get_lmax(w_dict,params)\n",
    "    Q_gw_w = np.zeros((L,lmax))\n",
    "    for W_il in W_ils_w:\n",
    "        Q_gw_w[<int> W_il[0],<int> W_il[1]] = W_il[2]\n",
    "    return Q_gw_w\n",
    "\n",
    "def get_Q_gw_i(double [:,:] Yseq, w_dict, double [:] params):\n",
    "    cdef int L = Yseq.shape[0]\n",
    "    cdef int lmax = get_lmax(w_dict,params)\n",
    "    cdef int D = len(w_dict)\n",
    "    Q_gw_i = np.zeros((lmax,D),dtype = float)\n",
    "    cdef double [:,:] Q_gw_i_view = Q_gw_i\n",
    "    cdef int l,w\n",
    "    #print(L,lmax,min(L,lmax),Yseq.shape[0])\n",
    "    for l in range(min(L,lmax)):\n",
    "        for w in range(D):\n",
    "            Q_gw_i_view[l,w] = P_YgS(Yseq[-l-1:],w_dict[w],params)\n",
    "            #print(l,w,Q_gw_i[l,w],Q_gw_i_view[l,w])\n",
    "    #sys.stdout.flush()\n",
    "    return Q_gw_i\n",
    "\n",
    "#@cython.boundscheck(False)\n",
    "#@cython.wraparound(False)\n",
    "def evaluate_Q(double[:] P_w, W_ils, int L, int lmax, int D):\n",
    "    Q = np.zeros((L,lmax), dtype=float)\n",
    "    cdef double[:,:] Q_view = Q\n",
    "    cdef int i,l,w,w_il_length\n",
    "    \n",
    "    for w in range(D):\n",
    "        for W_il in W_ils[w]:\n",
    "            i = <int> W_il[0]\n",
    "            l = <int> W_il[1]\n",
    "            Q_view[i,l] += P_w[w]*W_il[2]\n",
    "    return Q\n",
    "\n",
    "#@cython.boundscheck(False)\n",
    "#@cython.wraparound(False)\n",
    "def evaluate_R(double[:,:] Q):\n",
    "    cdef int L = Q.shape[0]\n",
    "    cdef int i,l,lmax\n",
    "    lmax = Q.shape[1]\n",
    "    R = np.zeros(L, dtype = float)\n",
    "    cdef double[:] R_view = R\n",
    "    cdef double prod = 1\n",
    "    for i in range(L):\n",
    "        R_view[i] = Q[i,0] + 1e-10\n",
    "        prod = 1\n",
    "        for l in range(1,min(lmax,i+1)):\n",
    "            prod *= R_view[i-l]\n",
    "            R_view[i] += Q[i,l]/prod\n",
    "    return R\n",
    "\n",
    "#@cython.boundscheck(False)\n",
    "#@cython.wraparound(False)\n",
    "def evaluate_R1(double[:,:] Q):\n",
    "    cdef int L = Q.shape[0]\n",
    "    cdef int i,l,lmax\n",
    "    lmax = Q.shape[1]\n",
    "    R1 = np.zeros(L, dtype = float)\n",
    "    cdef double[:] R1_view = R1\n",
    "    cdef double prod = 1\n",
    "    for i in range(L-1,-1,-1):\n",
    "        R1_view[i] = Q[i,0] + 1e-10\n",
    "        prod = 1\n",
    "        for l in range(1,min(lmax,L-i)):\n",
    "            prod *= R1_view[i+l]\n",
    "            R1_view[i] += Q[i+l,l]/prod\n",
    "    return R1\n",
    "\n",
    "#@cython.boundscheck(False)\n",
    "#@cython.wraparound(False)\n",
    "def evaluate_G(double [:] R,double [:] R1,int lmax):\n",
    "    cdef int L = R.shape[0]\n",
    "    G = np.zeros((L,lmax), dtype= float)\n",
    "    cdef double[:,:] G_view = G\n",
    "    cdef double prod = 1\n",
    "    cdef double prod2 = 1\n",
    "    cdef int i,l\n",
    "    for i in range(L):\n",
    "        prod *= R[i]/R1[i]\n",
    "        prod2 = 1\n",
    "        for l in range(min(lmax,i+1)):\n",
    "            prod2 *= R[i-l]\n",
    "            G_view[i,l] = prod/prod2\n",
    "    return G\n",
    "\n",
    "def evaluate_F(R):\n",
    "    return -np.sum(np.log(R))\n",
    "\n",
    "\n",
    "#@cython.boundscheck(False)\n",
    "#@cython.wraparound(False)\n",
    "def evaluate_dF(double[:] P_w, double[:,:] G, W_ils):\n",
    "    cdef int D = P_w.shape[0]\n",
    "    \n",
    "    dF = np.zeros(D, dtype = float)\n",
    "    \n",
    "    cdef double [::1] dF_view = dF\n",
    "    \n",
    "    cdef int i,l,w\n",
    "    \n",
    "    for w in range(D):\n",
    "        for W_il in W_ils[w]:\n",
    "            i = <int> W_il[0]\n",
    "            l = <int> W_il[1]\n",
    "            dF_view[w] += -G[i,l]*W_il[2] \n",
    "    return dF\n",
    "\n",
    "def evaluate_F_seq(Y,lengths_Y, P_w, w_dict, params):\n",
    "    lmax = get_lmax(w_dict,params)\n",
    "    L = Y.shape[0]\n",
    "    D = len(w_dict)\n",
    "    \n",
    "    W_ils = get_W_ils(w_dict, Y,lengths_Y, params)\n",
    "    Q = evaluate_Q(P_w,W_ils,L,lmax,D)\n",
    "    R = evaluate_R(Q)\n",
    "    F = evaluate_F(R)\n",
    "    return F\n",
    "\n",
    "#@cython.boundscheck(False)\n",
    "#@cython.wraparound(False)\n",
    "cpdef double subroutine_Nw1w2(np.int_t[:] w1w2, double [:,:] G, np.int_t [:] nz_pos, double [:,:] Q_gw1, double [:,:] Q_gw2, int l1,int l2, double [:] params):\n",
    "    cdef int L = G.shape[0]\n",
    "    cdef double Nw1w2 = 0\n",
    "    cdef double eps = params[0]\n",
    "    cdef double p_d = params[1]\n",
    "    cdef double temp\n",
    "    cdef int lenw1w2 = w1w2.shape[0]\n",
    "    if lenw1w2 == 0:\n",
    "        return 0.0\n",
    "    cdef int i,l,lmin,lmax,k\n",
    "    lmin,lmax = get_lmin_and_max(w1w2,params)\n",
    "    for i in nz_pos:\n",
    "        for l in range(lmin,min(lmax,i+1)):\n",
    "            temp = 0\n",
    "            temp += Q_gw2[i,l]*pow(eps*p_d,l1)\n",
    "            temp += Q_gw1[i,l]*pow(eps*p_d,l2)\n",
    "            for k in range(l):\n",
    "                temp += Q_gw2[i,k]*Q_gw1[i-k-1,l-k-1]\n",
    "            Nw1w2 += temp*G[i,l]\n",
    "    return Nw1w2\n",
    "\n",
    "def sample(S,params,model):\n",
    "    eps = params[0]\n",
    "    p_d = params[1]\n",
    "    p_ins = params[2]\n",
    "    Y = []\n",
    "    while len(Y) == 0:\n",
    "        if len(S) == 1:\n",
    "            Y += [model._generate_sample_from_state(S[0])]\n",
    "        else:\n",
    "            for s in S:\n",
    "                randu = np.random.uniform()\n",
    "                if randu < 1-eps:\n",
    "                    Y += [model._generate_sample_from_state(s)]\n",
    "                elif randu < 1-eps + eps*(1-p_d):\n",
    "                    numy = 2#np.random.geometric(1-p_ins)\n",
    "                    for j in range(numy):\n",
    "                        Y += [model._generate_sample_from_state(s)]\n",
    "    return Y\n",
    "\n",
    "def convert_Y_to_Y_Ps(Y,params,model):\n",
    "    Sigma = int(params[7])\n",
    "    Y_Ps = np.zeros((len(Y),Sigma),dtype = float)\n",
    "    Y_Ps = np.exp(model._compute_log_likelihood(Y))\n",
    "    return Y_Ps\n",
    "\n",
    "@cython.cdivision(True)\n",
    "def get_JS(w_dict,double [:] params, model):\n",
    "    cdef int niter = 500\n",
    "    cdef int D = len(w_dict)\n",
    "    cdef double [:,:] dij = np.zeros((D,D),dtype = float)\n",
    "    cdef double [:,:] dijT = np.zeros((D,D),dtype = float)\n",
    "    cdef double [:,:] JS = np.zeros((D,D),dtype = float)\n",
    "    \n",
    "    eps = params[0]\n",
    "    cdef np.int_t [:,:] editdist = np.zeros((D,D),dtype = int)\n",
    "    cdef int di,dj,i\n",
    "    cdef double dist\n",
    "    for di in range(D):\n",
    "        for dj in range(D):\n",
    "            str1 = ''.join(str(e) for e in w_dict[di])\n",
    "            str2 = ''.join(str(e) for e in w_dict[dj])\n",
    "            dist = editdistance.eval(str1, str2)\n",
    "            #print(str1,\" \",str2,dist,pow(eps,dist))\n",
    "            if dist > 0.0 and pow(eps,dist)*pow(1-eps,len(str1)-dist) < 1e-4:\n",
    "                editdist[di][dj] = 1\n",
    "                \n",
    "    cdef double YiSi,YiSj\n",
    "    cdef double [:,:] Ydi\n",
    "    for di in range(D):\n",
    "        for i in range(niter):\n",
    "            sample_di = np.array(sample(w_dict[di],params,model),dtype = float)\n",
    "            Ydi = convert_Y_to_Y_Ps(sample_di,params,model)\n",
    "            YiSi = P_YgS(Ydi,w_dict[di],params)\n",
    "            for dj in range(D):\n",
    "                if w_dict[di].shape[0] == 1 or w_dict[dj].shape[0] == 1 or editdist[di][dj]:\n",
    "                    dij[di,dj] = log(2)\n",
    "                else:\n",
    "                    YiSj = P_YgS(Ydi, w_dict[dj],params)\n",
    "                    dij[di,dj] += (log(YiSi) - log(0.5*YiSi + 0.5*YiSj))/niter\n",
    "    for di in range(D):\n",
    "        for dj in range(D):\n",
    "            JS[di][dj] = (dij[di,dj] + dij[dj,di])/(2*log(2))\n",
    "    return JS\n",
    "\n",
    "cpdef double P_YgHMM(double[:,:] Y, double[:,:] transmat_hmm, double[:] rho):\n",
    "    cdef int l = Y.shape[0]\n",
    "    cdef int Sigma = Y.shape[1]\n",
    "    alphas = np.zeros((l,Sigma),dtype = float)\n",
    "    cdef double [:,:] alphas_view = alphas\n",
    "    cdef double output = 0\n",
    "    cdef int i,s,sp\n",
    "    for i in range(l):\n",
    "        for s in range(Sigma):\n",
    "            if i == 0:\n",
    "                alphas_view[i,s] = Y[i,s]*rho[s]\n",
    "            else:\n",
    "                for sp in range(Sigma):\n",
    "                    alphas_view[i,s] += alphas_view[i-1,sp]*transmat_hmm[sp,s]\n",
    "                alphas_view[i,s] *= Y[i,s]\n",
    "    for s in range(Sigma):\n",
    "        output += alphas_view[-1,s]\n",
    "    return output\n",
    "\n",
    "def calculate_expected_frequency_hmm(seq,transmat,rho):\n",
    "    l = len(seq)\n",
    "    prob = 1\n",
    "    for i in range(l):\n",
    "        if i == 0:\n",
    "            prob *= rho[seq[i]]\n",
    "        else:\n",
    "            prob *= transmat[seq[i-1]][seq[i]]\n",
    "    return prob\n",
    "\n",
    "@cython.cdivision(True)\n",
    "@cython.boundscheck(False)\n",
    "cpdef double calculate_empirical_frequency_hmm(np.int_t [:] seq, double [:,:] Y, double [:,:] transmat_, double [:] stationary_probs_):\n",
    "    cdef int l = seq.shape[0]\n",
    "    cdef int L = Y.shape[0]\n",
    "    cdef double prob = calculate_expected_frequency_hmm(seq,transmat_, stationary_probs_)\n",
    "    cdef double counts = 0\n",
    "    cdef int i,j\n",
    "    cdef double count,likelihood\n",
    "    for i in range(L-l):\n",
    "        count = 1\n",
    "        for j in range(l):\n",
    "            count *= Y[i+j,seq[j]]\n",
    "        likelihood = P_YgHMM(Y[i:i+l],transmat_, stationary_probs_)\n",
    "        count /= likelihood\n",
    "        count *= prob\n",
    "        counts += count\n",
    "    return counts/(L-l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from scipy.stats import norm\n",
    "\n",
    "def create_word_array(ws,w_dict):\n",
    "    arr = np.array([])\n",
    "    for w in ws:\n",
    "        arr = np.concatenate((arr,w_dict[w]))\n",
    "    arr = np.array(arr,dtype = int)\n",
    "    return arr\n",
    "\n",
    "def Z_partitions(seq,P_w,w_dict):\n",
    "    L = len(seq)\n",
    "    D = len(w_dict)\n",
    "    lengths = [len(w) for w in w_dict]\n",
    "    lmax = np.max(lengths)\n",
    "    Z_p = np.zeros(L)\n",
    "    for i in range(L):\n",
    "        for l in range(min(i+1,lmax)):\n",
    "            for w in range(D):\n",
    "                if np.array_equal(seq[i-l:i+1],w_dict[w]):\n",
    "                    if i >= l+1:\n",
    "                        Z_p[i] += Z_p[i-l-1]*P_w[w]\n",
    "                    else:\n",
    "                        Z_p[i] += P_w[w]\n",
    "    return Z_p[-1] \n",
    "\n",
    "def Nw1w2(ws, P_w, w_dict, Y, Q, Q_gw1, Q_gw2, nz_pos, params):\n",
    "    arr = create_word_array(ws,w_dict)\n",
    "    lengths = [len(w) for w in w_dict]\n",
    "    l1 = len(w_dict[ws[0]])\n",
    "    l2 = len(w_dict[ws[1]])\n",
    "    \n",
    "    lmax = get_lmax([arr],params)\n",
    "    \n",
    "    R = evaluate_R(Q)\n",
    "    R1 = evaluate_R1(Q)\n",
    "    G = evaluate_G(R,R1,lmax)\n",
    "    \n",
    "    Fseq = -np.log(Z_partitions(arr,P_w,w_dict))\n",
    "    \n",
    "    N_calc = np.exp(-Fseq)*subroutine_Nw1w2(arr,G,nz_pos,Q_gw1,Q_gw2,l1,l2,params) + 1e-10\n",
    "    f_calc = N_calc/len(Y)\n",
    "    if N_calc < 5.0:\n",
    "        return 1.0\n",
    "    \n",
    "    lmean = np.sum(lengths*P_w)\n",
    "    N_exp = len(Y)*np.exp(-Fseq)/lmean + 1e-10\n",
    "    f_exp = N_exp/len(Y)\n",
    "    \n",
    "    q1 = 1 + (1.0/f_exp + 1.0/(1-f_exp) - 1)/(6.0*len(Y)) #correction to LR test\n",
    "    m2lnLR = 2*len(Y)*(f_calc*np.log(f_calc/f_exp) + (1-f_calc)*np.log((1-f_calc)/(1-f_exp)))/q1\n",
    "    return stats.chi2.sf(m2lnLR,1)\n",
    "\n",
    "def H_beta(betas,params):\n",
    "    Z = 1.0 + np.sum(np.exp(-betas))\n",
    "    return params[5]*(np.sum(betas*np.exp(-betas)/Z) + np.log(Z))/np.log(1 + len(betas))\n",
    "\n",
    "def dH_beta(betas,params):\n",
    "    Z = 1.0 + np.sum(np.exp(-betas))\n",
    "    return params[5]*((np.sum(betas*np.exp(-betas)/Z) - betas)*np.exp(-betas)/Z)/np.log(1 + len(betas))\n",
    "\n",
    "def F_beta(betas, W_ils, L, lmax, D, params):\n",
    "    P_w = np.zeros(len(betas)+1)\n",
    "    P_w[:-1] = np.exp(-betas)\n",
    "    P_w[-1] = 1.0\n",
    "    P_w /= np.sum(P_w)\n",
    "    for i in range(len(P_w)):\n",
    "        if P_w[i] != P_w[i]:\n",
    "            print(\"Error in F_beta\", i, betas[i])\n",
    "            sys.stdout.flush()\n",
    "    Q = evaluate_Q(P_w, W_ils, L, lmax, D)\n",
    "    R = evaluate_R(Q)\n",
    "    F = evaluate_F(R)\n",
    "    \n",
    "    return F/L + H_beta(betas,params)\n",
    "                                    \n",
    "def dF_beta(betas, W_ils, L, lmax, D,params):\n",
    "    P_w = np.zeros(D)\n",
    "    P_w[:-1] = np.exp(-betas)\n",
    "    P_w[-1] = 1.0\n",
    "    P_w /= np.sum(P_w)\n",
    "    \n",
    "    Q = evaluate_Q(P_w, W_ils, L, lmax, D)\n",
    "    R = evaluate_R(Q)\n",
    "    R1 = evaluate_R1(Q)\n",
    "    \n",
    "    G = evaluate_G(R,R1,lmax)\n",
    "    \n",
    "    dF_Pw = evaluate_dF(P_w, G, W_ils)\n",
    "    \n",
    "    dF_betas = np.zeros(len(betas))\n",
    "    for j in range(D-1):\n",
    "        dF_betas[j] = P_w[j]*(-dF_Pw[j] + np.sum(P_w*dF_Pw))\n",
    "        \n",
    "    return dF_betas/L + dH_beta(betas,params) \n",
    "\n",
    "#Minimizing free energy\n",
    "def minimize_F(Y, W_ils, L, lmax, D, params, method):\n",
    "    betas0 = 0.1*np.random.randn(D-1)\n",
    "    bounds = []\n",
    "    for i in range(len(betas0)):\n",
    "        bounds += [[-20.0,20.0]]\n",
    "    res = minimize(F_beta, betas0, args = (W_ils, L, lmax, D, params),method = method, jac = dF_beta, bounds = bounds, options = {'disp':False})\n",
    "    return res\n",
    "\n",
    "\n",
    "#Optimizing for P_w\n",
    "def get_P_w(Y, lengths_Y, w_dict, params,method = 'L-BFGS-B'):\n",
    "    lmax = get_lmax(w_dict, params)\n",
    "    L = len(Y)\n",
    "    D = len(w_dict)\n",
    "    W_ils = get_W_ils(w_dict, Y, lengths_Y, params)\n",
    "    res = minimize_F(Y,W_ils, L, lmax, D,params,method) \n",
    "    P_w_fit = np.zeros(D)\n",
    "    P_w_fit[:-1] = np.exp(-res.x)\n",
    "    P_w_fit[-1] = 1.0\n",
    "    P_w_fit /= np.sum(P_w_fit)\n",
    "    return P_w_fit\n",
    "\n",
    "#Decoding\n",
    "def decode_Y(Y,P_w,w_dict,params):\n",
    "    D = len(w_dict)\n",
    "    L = len(Y)\n",
    "    K = np.zeros(L)\n",
    "    lmax = get_lmax(w_dict,params)\n",
    "    decodedws = []\n",
    "    decodedls = []\n",
    "    argmaxws = np.zeros(L)\n",
    "    argmaxls = np.zeros(L)\n",
    "    for i in range(L):\n",
    "        l = min(i,lmax-1)\n",
    "        Q_gw_i = get_Q_gw_i(Y[i-l:i+1],w_dict,params)\n",
    "        if i == 0:\n",
    "            K[i] = np.log(np.max(P_w*Q_gw_i[0]))\n",
    "            argmaxws[0] = np.argmax(P_w*Q_gw_i[0])\n",
    "            argmaxls[0] = 0\n",
    "        else:\n",
    "            argmaxw = np.argmax(P_w*Q_gw_i,axis=1)\n",
    "            maxw = np.max(P_w*Q_gw_i,axis=1)\n",
    "            ls = []\n",
    "            for l in range(min(i+1,lmax)):\n",
    "                if l == i:\n",
    "                    ls += [np.log(maxw[l])]\n",
    "                else:\n",
    "                    ls += [np.log(maxw[l]) + K[i-l-1]]\n",
    "            argmaxl = np.argmax(ls)\n",
    "            K[i] = np.max(ls)\n",
    "            argmaxws[i] = argmaxw[argmaxl]\n",
    "            argmaxls[i] = argmaxl\n",
    "    i = L-1\n",
    "    while i >= 0:\n",
    "        decodedws += [int(argmaxws[int(i)])]\n",
    "        decodedls += [int(argmaxls[int(i)])+1]\n",
    "        i -= argmaxls[int(i)]+1\n",
    "    ws = np.array(decodedws[::-1])\n",
    "    ls = np.array(decodedls[::-1])\n",
    "    \n",
    "    w_ML = []\n",
    "    for w in ws:\n",
    "        w_ML += list(w_dict[w])\n",
    "    \n",
    "    return w_ML,ws,ls\n",
    "                 \n",
    "def decode(Y,lengths_Y,w_dict,params):\n",
    "    L = len(Y)\n",
    "    D = len(w_dict)\n",
    "    lmax = get_lmax(w_dict,params)\n",
    "    P_w = get_P_w(Y, lengths_Y, w_dict, params)\n",
    "    \n",
    "    kk = 0\n",
    "    w_MLs = []\n",
    "    words = []\n",
    "    wordlengths = []\n",
    "    for lths in lengths_Y:\n",
    "        w_ML,ws,ls = decode_Y(Y[kk:kk+lths],P_w,w_dict,params)\n",
    "        w_MLs += [w_ML]\n",
    "        words += [ws]\n",
    "        wordlengths += [ls]\n",
    "        kk += lths\n",
    "    return w_MLs,words,wordlengths\n",
    "\n",
    "#Generating synthetic data\n",
    "\n",
    "def generate_Y(L, P_w, w_dict, params, model):\n",
    "    l = 0\n",
    "    Y = []\n",
    "    ws = []\n",
    "    words_true = []\n",
    "    while l < L:\n",
    "        w = np.random.choice(len(P_w), 1, p=P_w)[0]\n",
    "        ws += list(w_dict[w])\n",
    "        words_true += [w]\n",
    "        S = sample(w_dict[w],params,model)\n",
    "        Y = Y + S\n",
    "        l += len(S)\n",
    "    Ydata = np.array(Y)\n",
    "    return convert_Y_to_Y_Ps(Y,params,model),words_true,Ydata\n",
    "    \n",
    "    \n",
    "def generate_w_dict(alphfreqs, D, lmean):\n",
    "    w_dict= []\n",
    "    alphabetsize = len(alphfreqs)\n",
    "    flag = 0\n",
    "    while len(w_dict) < D:\n",
    "        numletters = poisson.rvs(lmean)#np.random.geometric(1.0/lmean)#\n",
    "        while numletters < 2:\n",
    "            numletters = poisson.rvs(lmean)#np.random.geometric(1.0/lmean)\n",
    "        w = np.zeros(numletters)\n",
    "        for j in range(numletters):\n",
    "            w[j] = np.random.choice(alphabetsize, 1, p=alphfreqs)[0]\n",
    "        \n",
    "        for ww in w_dict:\n",
    "            if len(w) == len(ww) and np.prod((w == ww)):\n",
    "                flag = 1\n",
    "        if flag == 1:\n",
    "            flag = 0\n",
    "            continue\n",
    "        w_dict += [w]\n",
    "    for i in range(alphabetsize):\n",
    "        w_dict += [np.array([i])]\n",
    "    w_dict = [np.array(w, dtype = int) for w in w_dict]\n",
    "    return w_dict\n",
    "\n",
    "def remove_duplicates_w_dict(P_w,w_dict,params,model):\n",
    "    eps = params[0]\n",
    "    dups = []\n",
    "    if eps > 1e-3:\n",
    "        JS = get_JS(w_dict,params,model)\n",
    "        Jthr = params[6]\n",
    "        P_w_weighted = np.sum((JS < Jthr)*P_w,axis=1)\n",
    "        \n",
    "        for i in range(len(w_dict)):#Remove duplicates\n",
    "            for j in range(i+1,len(w_dict)): \n",
    "                if JS[i][j] < Jthr and P_w_weighted[i] >= P_w_weighted[j]:\n",
    "                    dups += [j]\n",
    "                elif JS[i][j] < Jthr and P_w_weighted[i] < P_w_weighted[j]:\n",
    "                    dups += [i]\n",
    "                    break\n",
    "    else:\n",
    "        for i in range(len(w_dict)):#Remove duplicates\n",
    "            for j in range(i+1,len(w_dict)): \n",
    "                if np.array_equal(w_dict[i],w_dict[j]):\n",
    "                    dups += [j]\n",
    "        \n",
    "    dups = np.array(dups)\n",
    "    dups = np.unique(dups)                \n",
    "    print(dups)\n",
    "    for j in range(len(dups)):\n",
    "        del w_dict[dups[j]]\n",
    "        dups -= 1\n",
    "    return w_dict\n",
    "\n",
    "def truncate_w_dict(P_w,w_dict,thr = 5e-4): \n",
    "    i = 0\n",
    "    P_w = list(P_w)\n",
    "    while i < len(w_dict):#Remove low probability words\n",
    "        if P_w[i] < thr and len(w_dict[i]) > 1:\n",
    "            del w_dict[i]\n",
    "            del P_w[i]\n",
    "            i-=1\n",
    "        i+=1\n",
    "    return w_dict\n",
    "\n",
    "def prune_w_dict(Y,lengths_Y, w_dict, params,model):\n",
    "    D = len(w_dict)\n",
    "    Dnew = 0\n",
    "    i=0\n",
    "    P_w = get_P_w(Y,lengths_Y, w_dict, params)\n",
    "    w_dict = remove_duplicates_w_dict(P_w,w_dict,params,model)\n",
    "\n",
    "    while Dnew != D and i < 1: #changed from 10 to 1\n",
    "        D = len(w_dict)\n",
    "        P_w = get_P_w(Y,lengths_Y, w_dict, params)\n",
    "        lengths = [len(w) for w in w_dict]\n",
    "        lmean = np.sum(lengths*P_w)\n",
    "        thr = 5*lmean/len(Y) \n",
    "        w_dict = truncate_w_dict(P_w,w_dict,thr)\n",
    "        Dnew = len(w_dict)\n",
    "        i+=1\n",
    "        #print(i, D, Dnew)\n",
    "    return w_dict\n",
    "\n",
    "def prune_letters_w_dict(Y,P_w,w_dict): \n",
    "    lengths = [len(w) for w in w_dict]\n",
    "    lmean = np.sum(lengths*P_w)\n",
    "    thr = 5*lmean/len(Y) #This is a parameter\n",
    "    \n",
    "    P_w = list(P_w)\n",
    "    i = 0\n",
    "    while i < len(w_dict):#Remove low probability words\n",
    "        if P_w[i] < thr and len(w_dict[i]) == 1: \n",
    "            del w_dict[i]\n",
    "            del P_w[i]\n",
    "            i-=1\n",
    "        i+=1\n",
    "    return w_dict\n",
    "\n",
    "\n",
    "def get_words_to_add(Y,lengths_Y,w_dict,params):\n",
    "    words_to_add = []\n",
    "    P_w = get_P_w(Y,lengths_Y, w_dict, params)\n",
    "    lengths = [len(w) for w in w_dict]\n",
    "    L = len(Y)\n",
    "    lmax = get_lmax(w_dict,params)\n",
    "    D = len(w_dict)\n",
    "    W_ils = get_W_ils(w_dict, Y,lengths_Y, params)\n",
    "    Q = evaluate_Q(P_w, W_ils, L, lmax, D)\n",
    "    \n",
    "    R = evaluate_R(Q)\n",
    "    R1 = evaluate_R1(Q)\n",
    "    G = evaluate_G(R,R1,lmax)\n",
    "    w_thr = params[4]\n",
    "    lmean = np.sum(P_w*lengths)\n",
    "    for ibeta in range(len(w_dict)):\n",
    "        lmin,lmax = get_lmin_and_max(w_dict[ibeta],params)\n",
    "        Nw1w2_arr = np.zeros(len(w_dict))\n",
    "        Q_gw2 = get_Q_gw_from_W_il(W_ils[ibeta],Y,w_dict,params)\n",
    "        \n",
    "        nz_pos = np.nonzero(np.sum(Q_gw2[:,lmin:lmax],axis=1) > w_thr)\n",
    "        nz_pos = np.array(nz_pos[0],dtype = int)\n",
    "        \n",
    "        for ialpha in range(len(w_dict)):\n",
    "            Q_gw1 = get_Q_gw_from_W_il(W_ils[ialpha],Y,w_dict,params)\n",
    "            ws = [ialpha,ibeta]\n",
    "            arr = create_word_array(ws,w_dict)\n",
    "            if len(arr) > 20: #This is a parameter\n",
    "                continue\n",
    "            pvalue_ij = Nw1w2(ws,P_w,w_dict,Y,Q,Q_gw1,Q_gw2,nz_pos, params)\n",
    "            if pvalue_ij < 5e-2:\n",
    "                words_to_add += [arr]\n",
    "                \n",
    "    return words_to_add\n",
    "\n",
    "def update_w_dict(Y,lengths_Y,w_dict,params,model):\n",
    "    words_to_add = get_words_to_add(Y,lengths_Y,w_dict,params)                    \n",
    "    w_dict = w_dict + words_to_add\n",
    "    print(\"Dictionary length %d\" %len(w_dict))\n",
    "    w_dict = prune_w_dict(Y,lengths_Y,w_dict,params,model)\n",
    "    print(\"Pruned length %d\" %len(w_dict))\n",
    "    sys.stdout.flush()\n",
    "    return w_dict\n",
    "\n",
    "def get_entropy(Y):\n",
    "    P_S = np.zeros(Y.shape[1])\n",
    "    P_Y = np.sum(Y,axis=1)\n",
    "    P_Si = np.mean(Y/P_Y[:,np.newaxis],axis=0)\n",
    "    P_Yi = np.sum(Y*P_Si,axis=1)\n",
    "    entropy = np.mean(-P_Yi*np.log(P_Yi+1e-15))\n",
    "    return entropy\n",
    "    \n",
    "def solve_dictionary(Y,lengths_Y,params,model,niter = 6):\n",
    "    if np.sum(lengths_Y) != len(Y) or np.min(lengths_Y) <= 0:\n",
    "        print(\"Invalid lengths_Y\", np.sum(lengths_Y), len(Y))\n",
    "        sys.stdout.flush()\n",
    "        return \n",
    "    \n",
    "    w_dict = []\n",
    "    Sigma = Y.shape[1]\n",
    "\n",
    "    for i in range(Sigma):\n",
    "        w_dict += [np.array([i], dtype = int)]\n",
    "        \n",
    "    P_w = get_P_w(Y,lengths_Y,w_dict,params)\n",
    "    \n",
    "    Fs = np.zeros(niter+1)\n",
    "    Fs[0] = evaluate_F_seq(Y,lengths_Y,P_w, w_dict, params)/len(Y)\n",
    "    \n",
    "    w_dict = prune_w_dict(Y,lengths_Y,w_dict,params,model)\n",
    "    \n",
    "    for i in range(niter):\n",
    "        w_dict = update_w_dict(Y,lengths_Y,w_dict,params,model)\n",
    "        P_w = get_P_w(Y,lengths_Y,w_dict,params)\n",
    "        Ftrain = evaluate_F_seq(Y, lengths_Y,P_w, w_dict, params)/len(Y)\n",
    "        Fs[i+1] = Ftrain \n",
    "        #Fvalid = evaluate_F_seq(Yvalid, P_w, w_dict, params)/len(Yvalid)\n",
    "        w_dict_list = [list(w) for w in w_dict]\n",
    "        print(\"%d iter, w_dict length = %d, Train -logL = %.3f\" %(i+1,len(w_dict),Ftrain))\n",
    "        sys.stdout.flush()\n",
    "        if i == niter - 1 or (i > 1 and abs(Fs[i] - Fs[i+1]) < 0.002 and abs(Fs[i-1] - Fs[i]) < 0.002):\n",
    "            w_dict = prune_letters_w_dict(Y,P_w,w_dict)\n",
    "            #params[3] = 1.0\n",
    "            w_dict = prune_w_dict(Y,lengths_Y,w_dict,params,model)\n",
    "            P_w = get_P_w(Y, lengths_Y, w_dict, params)\n",
    "            break\n",
    "    print(\"Final length of w_dict = %d\" %(len(w_dict)))\n",
    "    #Ftest = evaluate_F_seq(Ytest, P_w, w_dict, params)/len(Ytest)\n",
    "    print(\"Done, w_dict length = %d\" %(len(w_dict)))\n",
    "    return P_w,w_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_explo_hmm = np.load(\"data_explo_hmm.npy\")\n",
    "data_dbsharppH_hmm = np.load(\"data_dbsharppH_hmm.npy\")\n",
    "\n",
    "lengths_explo_hmm = np.load(\"lengths_explo_hmm.npy\")\n",
    "lengths_dbsharppH_hmm = np.load(\"lengths_dbsharppH_hmm.npy\")\n",
    "\n",
    "model_fit = GMM_model(7)\n",
    "\n",
    "means_ = np.load(\"acid_means.npy\")\n",
    "covars_ = np.load(\"acid_covars.npy\")\n",
    "weights_ = np.load(\"acid_weights.npy\")\n",
    "model_fit._read_params(means_,covars_,weights_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.8199   4.83     0.6768 -37.3117  -5.4328  -4.853 ]\n",
      " [  5.535    8.0303   1.7934 -26.8663  -6.4542   0.4308]\n",
      " [ 19.3504   8.4985   1.4685  -5.2551  13.3825  11.6932]\n",
      " [ 29.4595  13.679    3.4338  26.3741  21.7379  14.4568]\n",
      " [ 45.0659   9.9905   2.2201  77.3159  16.9334  -8.8385]\n",
      " [ 73.9662  13.199    3.7417 147.0005 -32.5582  -5.9867]\n",
      " [ 82.7462  22.3344   5.518  101.5252  -4.2483  29.5516]]\n",
      "[[0.4754 0.1114 0.1877 0.0341 0.1243 0.0548 0.0123]\n",
      " [0.3888 0.1805 0.1441 0.0867 0.1061 0.0629 0.0309]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision = 4, suppress = True)\n",
    "print(model_fit.means_[np.argsort(model_fit.means_[:,0])])\n",
    "print(model_fit.weights_[:,np.argsort(model_fit.means_[:,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "lengths_explo = lengths_explo_hmm[:]\n",
    "data_explo = data_explo_hmm[:np.sum(lengths_explo)]\n",
    "\n",
    "Hexplo = -model_fit.score(data_explo,0)/len(data_explo) #entropy\n",
    "Yexplo = np.exp(model_fit._compute_log_likelihood(data_explo) + Hexplo)\n",
    "\n",
    "lengths_dbsharppH = lengths_dbsharppH_hmm[:]\n",
    "data_dbsharppH = data_dbsharppH_hmm[:np.sum(lengths_dbsharppH)]\n",
    "\n",
    "HdbsharppH = -model_fit.score(data_dbsharppH,1)/len(data_dbsharppH) #entropy\n",
    "YdbsharppH = np.exp(model_fit._compute_log_likelihood(data_dbsharppH))/np.exp(-HdbsharppH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load learned dictionaries for explo and acid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1]), array([3]), array([2]), array([3, 3]), array([6]), array([2, 3]), array([1, 3]), array([3, 1, 3]), array([4]), array([6, 6]), array([2, 4]), array([3, 3, 3, 3]), array([5]), array([4, 3]), array([2, 3, 3, 3]), array([4, 2]), array([2, 2]), array([3, 3, 1, 3, 3]), array([4, 4]), array([5, 6]), array([1, 2]), array([3, 3, 1, 3]), array([3, 3, 1, 3, 3, 3]), array([2, 3, 2]), array([6, 6, 6, 6]), array([3, 3, 3, 3, 3, 3, 3]), array([3, 0]), array([3, 3, 1, 3, 3, 3, 3, 3]), array([3, 3, 3, 3, 3, 3, 1, 3]), array([0, 3]), array([6, 6, 6, 6, 6, 6, 6]), array([5, 6, 6, 6]), array([4, 6]), array([6, 6, 6]), array([6, 6, 6, 5]), array([0, 5]), array([2, 3, 2, 3]), array([6, 5]), array([5, 0]), array([5, 4]), array([0, 4]), array([4, 0]), array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3]), array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]), array([6, 4]), array([6, 5, 6, 5]), array([2, 2, 2, 2]), array([1, 1, 1, 1]), array([5, 6, 6, 5]), array([6, 6, 5, 6]), array([5, 5, 6, 5]), array([5, 5]), array([5, 6, 5, 6]), array([5, 5, 5, 5]), array([6, 5, 6, 6]), array([6, 5, 5, 5]), array([6, 6, 5, 5]), array([0, 3, 3]), array([5, 5, 5, 6]), array([0]), array([0, 3, 3, 3]), array([5, 6, 5]), array([0, 4, 1]), array([1, 0, 4, 1]), array([6, 5, 5, 6]), array([3, 0, 5])]\n",
      "[array([1]), array([3]), array([2]), array([6]), array([3, 3]), array([4]), array([6, 6]), array([3, 3, 3, 3]), array([3, 6]), array([5]), array([4, 4]), array([2, 4]), array([2, 3, 3]), array([1, 3, 1]), array([2, 2]), array([3, 3, 3, 1]), array([5, 6]), array([2, 3, 1]), array([4, 2]), array([3, 3, 1, 3, 3]), array([3, 2, 3, 3]), array([3, 1, 3, 1]), array([3, 4]), array([6, 5]), array([3, 1, 3, 3]), array([6, 6, 6, 6]), array([0, 4]), array([5, 4]), array([2, 3, 2]), array([0, 5]), array([5, 5]), array([3, 3, 3, 1, 3, 3, 3, 3]), array([3, 0]), array([5, 0]), array([6, 6, 6, 5]), array([3, 2, 3, 2]), array([6, 6, 6]), array([3, 3, 3, 3, 3, 3]), array([4, 0]), array([3, 3, 3, 3, 3, 1, 3, 3]), array([3, 3, 3, 3, 3, 3, 3, 3]), array([3, 5]), array([6, 6, 5, 6]), array([5, 6, 6, 6]), array([0, 6]), array([6, 6, 6, 6, 6, 6, 6]), array([5, 6, 6, 5]), array([0, 3]), array([5, 5, 5, 5]), array([4, 6]), array([1, 0]), array([5, 5, 6, 5]), array([6, 5, 6, 6]), array([1, 1, 1, 1]), array([5, 6, 5, 5]), array([2, 2, 2, 2]), array([0, 5, 5, 5]), array([3, 3, 3, 1, 3, 3]), array([5, 0, 0, 5]), array([6, 5, 6, 5]), array([0, 1]), array([6, 6, 6, 5, 6, 6, 6, 6]), array([3, 3, 2, 3, 3]), array([0, 4, 5, 5]), array([5, 5, 5, 6]), array([2, 2, 3, 2]), array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]), array([6, 6, 6, 6, 6, 6, 6, 5]), array([0, 0]), array([5, 4, 5, 5]), array([5, 6, 5]), array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]), array([5, 6, 5, 6]), array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]), array([0, 5, 0, 5]), array([5, 0, 5, 5]), array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]), array([5, 6, 6, 6, 6, 6, 6, 6]), array([5, 5, 0, 5]), array([0]), array([0, 0, 3])]\n"
     ]
    }
   ],
   "source": [
    "eps = 0.1\n",
    "p_d = 0.2\n",
    "Jthr = 0.3\n",
    "seed = 1\n",
    "filename = \"./motifs_compare/motifs_explo_compare_eps%.2f_pd%.2f_Jthr%.2f_%d.dat\" %(eps,p_d,Jthr,seed)\n",
    "f=open(filename, 'r')\n",
    "\n",
    "#read dictionary for explo\n",
    "w_dict_explo = []\n",
    "flag = 0\n",
    "for lines in f:\n",
    "    a = lines.split()\n",
    "    if len(a) > 1 and flag == 1:\n",
    "        if a[0] == \"non-Markovianity:\":\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            numletters = len(a) - 2\n",
    "            word = []\n",
    "            if numletters == 1:\n",
    "                word += [int(a[2][1])]\n",
    "            if numletters > 1:\n",
    "                for i in range(numletters):\n",
    "                    if i == 0:\n",
    "                        word += [int(a[2+i][1])]\n",
    "                    elif i == numletters - 1:\n",
    "                        word += [int(a[2+i][0])]\n",
    "                    else:\n",
    "                        word += [int(a[2+i])]\n",
    "            \n",
    "            #print(word)\n",
    "            w_dict_explo += [np.array(word)]\n",
    "    if len(a) > 1 and a[0] == \"Explo\":\n",
    "        flag = 1\n",
    "print(w_dict_explo)\n",
    "\n",
    "eps = 0.1\n",
    "p_d = 0.2\n",
    "Jthr = 0.3\n",
    "seed = 1\n",
    "filename = \"./motifs_compare/motifs_acid_compare_eps%.2f_pd%.2f_Jthr%.2f_%d.dat\" %(eps,p_d,Jthr,seed)\n",
    "f=open(filename, 'r')\n",
    "\n",
    "#read dictionary for acid\n",
    "w_dict_dbsharppH = []\n",
    "flag = 0\n",
    "for lines in f:\n",
    "    a = lines.split()\n",
    "    if len(a) > 1 and flag == 1:\n",
    "        if a[0] == \"non-Markovianity:\":\n",
    "            flag = 0\n",
    "            continue\n",
    "        else:\n",
    "            numletters = len(a) - 2\n",
    "            word = []\n",
    "            if numletters == 1:\n",
    "                word += [int(a[2][1])]\n",
    "            if numletters > 1:\n",
    "                for i in range(numletters):\n",
    "                    if i == 0:\n",
    "                        word += [int(a[2+i][1])]\n",
    "                    elif i == numletters - 1:\n",
    "                        word += [int(a[2+i][0])]\n",
    "                    else:\n",
    "                        word += [int(a[2+i])]\n",
    "            \n",
    "            #print(word)\n",
    "            w_dict_dbsharppH += [np.array(word)]\n",
    "    if len(a) > 1 and a[0] == \"Acid\":\n",
    "        flag = 1\n",
    "print(w_dict_dbsharppH)\n",
    "\n",
    "w_thr = 1e-4\n",
    "p_ins = 0.2\n",
    "mu = 1.0\n",
    "H_beta_fac = 0\n",
    "Sigma = Yexplo.shape[1]\n",
    "std = 0.05\n",
    "params = np.array([eps,p_d,p_ins, mu, w_thr,H_beta_fac, Jthr, Sigma, std], dtype =float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute MLE motif probabilities for the two data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bfffebb7a5ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mP_w_explo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_P_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYexplo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths_explo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_dict_explo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mP_w_dbsharppH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_P_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYdbsharppH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths_dbsharppH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_dict_dbsharppH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-dc4ff1a4c522>\u001b[0m in \u001b[0;36mget_P_w\u001b[0;34m(Y, lengths_Y, w_dict, params, method)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mW_ils\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_W_ils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize_F\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW_ils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mP_w_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mP_w_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-dc4ff1a4c522>\u001b[0m in \u001b[0;36mminimize_F\u001b[0;34m(Y, W_ils, L, lmax, D, params, method)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mbounds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW_ils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdF_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'disp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 603\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    604\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-dc4ff1a4c522>\u001b[0m in \u001b[0;36mdF_beta\u001b[0;34m(betas, W_ils, L, lmax, D, params)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mP_w\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_ils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_R\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mR1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_R1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "P_w_explo = get_P_w(Yexplo,lengths_explo,w_dict_explo,params)\n",
    "P_w_dbsharppH = get_P_w(YdbsharppH,lengths_dbsharppH,w_dict_dbsharppH,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find threshold on -log_10 p for 10% false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131]\n",
      "66 66 66\n",
      "0894 0535 38.96 [1 3]\n",
      "0283 0463 22.15 [2 2]\n",
      "0666 0471 15.13 [3 3 3 3]\n",
      "0017 0056 13.02 [6 6 5 5]\n",
      "0082 0158 12.83 [1 2]\n",
      "2339 2008 12.68 [3 3]\n",
      "0343 0251 6.83 [4 3]\n",
      "0472 0365 6.67 [3 1 3]\n",
      "0114 0070 5.05 [0 3]\n",
      "0153 0103 4.77 [3 3 1 3 3 3]\n",
      "0069 0037 4.66 [5 4]\n",
      "0064 0037 3.57 [2 2 2 2]\n",
      "0030 0050 3.10 [1 1 1 1]\n",
      "0230 0181 3.05 [3 3 1 3 3]\n",
      "0078 0051 3.05 [0 4]\n",
      "0027 0044 2.62 [6 6 5 6]\n",
      "0031 0016 2.43 [6 5 6 5]\n",
      "0036 0054 2.23 [2 3 2 3]\n",
      "0060 0082 2.17 [5 6 6 6]\n",
      "0042 0061 2.11 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0027 0041 1.84 [6 5 6 6]\n",
      "0078 0101 1.83 [6 6 6 6 6 6 6]\n",
      "0042 0028 1.81 [5 6 6 5]\n",
      "0134 0162 1.71 [6 6 6 6]\n",
      "0136 0162 1.57 [6 6 6]\n",
      "0432 0387 1.56 [6 6]\n",
      "0271 0307 1.51 [2 3 3 3]\n",
      "0080 0062 1.40 [3 3 3 3 3 3 3 3 3 3]\n",
      "0021 0031 1.39 [6 5 5 6]\n",
      "0022 0032 1.31 [5 5 5 6]\n",
      "0115 0096 1.19 [3 0]\n",
      "0074 0061 1.00 [6 5]\n",
      "0082 0097 0.97 [3 3 3 3 3 3 1 3]\n",
      "0083 0098 0.93 [2 3 2]\n",
      "0110 0095 0.85 [3 3 1 3]\n",
      "0047 0038 0.77 [5 5 5 5]\n",
      "0078 0067 0.70 [5 0]\n",
      "0053 0063 0.69 [5 5]\n",
      "0303 0282 0.69 [4 4]\n",
      "0052 0043 0.65 [6 4]\n",
      "0133 0121 0.54 [3 3 3 3 3 3 3]\n",
      "0027 0022 0.50 [6 5 5 5]\n",
      "0072 0079 0.41 [3 3 1 3 3 3 3 3]\n",
      "0071 0064 0.39 [4 6]\n",
      "0057 0062 0.32 [6 6 6 5]\n",
      "0023 0027 0.30 [5 5 6 5]\n",
      "0013 0015 0.28 [0 4 1]\n",
      "0059 0055 0.21 [4 0]\n",
      "0160 0154 0.19 [5 6]\n",
      "0068 0071 0.18 [0 5]\n",
      "0010 0011 0.13 [3 0 5]\n",
      "0252 0257 0.11 [4 2]\n",
      "0757 0764 0.09 [2 3]\n",
      "0027 0028 0.06 [5 6 5]\n",
      "0366 0364 0.03 [2 4]\n",
      "[ 66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131]\n",
      "66 66 66\n",
      "0040 0113 20.27 [3 3 1 3 3 3 3 3]\n",
      "0142 0047 19.60 [3 3 1 3]\n",
      "2108 2449 13.43 [3 3]\n",
      "0060 0126 12.70 [3 3 3 3 3 3 1 3]\n",
      "0381 0497 7.97 [3 1 3]\n",
      "0065 0025 7.87 [5 5 5 5]\n",
      "0161 0095 7.78 [3 3 3 3 3 3 3]\n",
      "0174 0248 6.92 [3 3 1 3 3]\n",
      "0059 0024 6.78 [6 6 5 5]\n",
      "0099 0152 6.04 [1 2]\n",
      "0043 0078 5.92 [5 5]\n",
      "0479 0381 5.57 [6 6]\n",
      "0053 0024 5.19 [6 6 5 6]\n",
      "0070 0110 5.16 [0 3]\n",
      "0274 0348 4.80 [4 3]\n",
      "0038 0017 3.94 [6 5 6 5]\n",
      "0039 0017 3.87 [6 5 5 6]\n",
      "0113 0076 3.66 [6 6 6 6 6 6 6]\n",
      "0092 0059 3.62 [3 3 3 3 3 3 3 3 3 3]\n",
      "0133 0177 3.47 [6 6 6]\n",
      "0347 0415 3.44 [2 2]\n",
      "0704 0799 3.44 [1 3]\n",
      "0062 0036 3.43 [2 3 2 3]\n",
      "0078 0051 2.93 [6 6 6 5]\n",
      "0034 0017 2.87 [6 5 5 5]\n",
      "0084 0057 2.78 [0 5]\n",
      "0035 0019 2.67 [5 5 6 5]\n",
      "0086 0059 2.67 [6 5]\n",
      "0031 0016 2.66 [0 3 3]\n",
      "0064 0042 2.53 [5 4]\n",
      "0292 0245 2.39 [4 2]\n",
      "0554 0613 1.86 [3 3 3 3]\n",
      "0086 0064 1.83 [5 0]\n",
      "0148 0119 1.83 [3 3 1 3 3 3]\n",
      "0082 0104 1.70 [2 3 2]\n",
      "0165 0140 1.35 [6 6 6 6]\n",
      "0028 0039 1.20 [5 6 6 5]\n",
      "0059 0050 0.64 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0019 0015 0.52 [5 6 5 6]\n",
      "0024 0030 0.51 [5 6 5]\n",
      "0313 0296 0.51 [4 4]\n",
      "0155 0167 0.50 [5 6]\n",
      "0012 0015 0.45 [0 3 3 3]\n",
      "0024 0029 0.44 [5 5 5 6]\n",
      "0368 0385 0.42 [2 4]\n",
      "0798 0774 0.42 [2 3]\n",
      "0049 0053 0.26 [6 4]\n",
      "0306 0297 0.23 [2 3 3 3]\n",
      "0066 0071 0.22 [0 4]\n",
      "0071 0075 0.20 [5 6 6 6]\n",
      "0070 0067 0.17 [4 6]\n",
      "0036 0034 0.11 [6 5 6 6]\n",
      "0110 0109 0.04 [3 0]\n",
      "0043 0044 0.04 [1 1 1 1]\n",
      "0059 0059 0.03 [4 0]\n",
      "0053 0053 0.00 [2 2 2 2]\n",
      "[ 66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131]\n",
      "66 66 66\n",
      "0047 0139 26.64 [2 3 2]\n",
      "0073 0158 17.47 [1 2]\n",
      "0172 0074 16.54 [3 3 3 3 3 3 3]\n",
      "0110 0183 9.49 [6 6 6]\n",
      "0816 0669 7.24 [2 3]\n",
      "0451 0343 7.09 [6 6]\n",
      "0092 0046 6.97 [3 3 3 3 3 3 3 3 3 3]\n",
      "2222 2016 5.48 [3 3]\n",
      "0329 0252 5.12 [4 3]\n",
      "0150 0100 4.97 [3 3 1 3 3 3]\n",
      "0016 0035 4.14 [6 5 5 6]\n",
      "0637 0738 4.11 [1 3]\n",
      "0064 0036 3.93 [5 4]\n",
      "0051 0028 3.41 [1 1 1 1]\n",
      "0071 0047 2.58 [6 6 6 5]\n",
      "0103 0074 2.53 [3 3 3 3 3 3 1 3]\n",
      "0111 0086 1.83 [3 3 1 3]\n",
      "0304 0263 1.79 [4 4]\n",
      "0236 0268 1.41 [4 2]\n",
      "0062 0047 1.36 [5 5]\n",
      "0185 0213 1.34 [3 3 1 3 3]\n",
      "0131 0154 1.27 [6 6 6 6]\n",
      "0083 0066 1.24 [3 3 1 3 3 3 3 3]\n",
      "0063 0048 1.24 [4 0]\n",
      "0082 0099 1.13 [0 3]\n",
      "0392 0428 1.11 [3 1 3]\n",
      "0078 0063 1.10 [5 6 6 6]\n",
      "0020 0029 1.10 [6 5 6 5]\n",
      "0028 0019 1.07 [6 5 5 5]\n",
      "0020 0028 1.02 [5 5 5 6]\n",
      "0345 0376 1.01 [2 2]\n",
      "0013 0020 1.01 [5 6 5 6]\n",
      "0075 0062 0.97 [6 5]\n",
      "0047 0037 0.88 [5 5 5 5]\n",
      "0073 0061 0.85 [4 6]\n",
      "0339 0365 0.76 [2 4]\n",
      "0023 0030 0.76 [5 5 6 5]\n",
      "0030 0038 0.73 [5 6 6 5]\n",
      "0054 0045 0.69 [2 2 2 2]\n",
      "0037 0030 0.63 [6 6 5 6]\n",
      "0063 0073 0.60 [0 5]\n",
      "0092 0082 0.58 [6 6 6 6 6 6 6]\n",
      "0073 0067 0.33 [5 0]\n",
      "0060 0065 0.27 [0 4]\n",
      "0048 0052 0.26 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0047 0044 0.23 [6 4]\n",
      "0101 0106 0.22 [3 0]\n",
      "0547 0536 0.21 [3 3 3 3]\n",
      "0034 0031 0.19 [6 5 6 6]\n",
      "0283 0277 0.14 [2 3 3 3]\n",
      "0036 0034 0.09 [6 6 5 5]\n",
      "0151 0153 0.08 [5 6]\n",
      "0014 0015 0.07 [0 3 3 3]\n",
      "[ 66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131]\n",
      "66 66 66\n",
      "0529 0360 14.53 [3 1 3]\n",
      "0348 0480 10.71 [6 6]\n",
      "0126 0063 9.19 [3 3 3 3 3 3 1 3]\n",
      "0072 0026 9.06 [6 4]\n",
      "0055 0017 8.80 [6 6 5 6]\n",
      "2334 2081 7.61 [3 3]\n",
      "0844 0697 7.00 [2 3]\n",
      "0509 0620 5.78 [3 3 3 3]\n",
      "0322 0409 5.48 [2 4]\n",
      "0101 0151 5.33 [3 3 3 3 3 3 3]\n",
      "0259 0330 4.69 [4 4]\n",
      "0037 0064 4.40 [5 4]\n",
      "0090 0055 3.95 [3 3 3 3 3 3 3 3 3 3]\n",
      "0057 0032 3.38 [5 5 5 5]\n",
      "0046 0071 3.22 [5 5]\n",
      "0052 0079 3.13 [0 4]\n",
      "0333 0275 3.05 [4 3]\n",
      "0064 0040 2.82 [2 2 2 2]\n",
      "0116 0085 2.52 [2 3 2]\n",
      "0032 0017 2.32 [0 3 3]\n",
      "0021 0010 2.22 [0 4 1]\n",
      "0059 0081 2.16 [6 5]\n",
      "0689 0760 2.14 [1 3]\n",
      "0102 0077 2.11 [0 3]\n",
      "0020 0032 1.81 [6 5 6 5]\n",
      "0349 0389 1.50 [2 2]\n",
      "0246 0276 1.26 [4 2]\n",
      "0031 0021 1.16 [5 5 6 5]\n",
      "0021 0029 1.12 [5 5 5 6]\n",
      "0020 0028 1.06 [6 5 5 5]\n",
      "0221 0198 0.98 [3 3 1 3 3]\n",
      "0147 0165 0.90 [5 6]\n",
      "0031 0040 0.86 [5 6 6 5]\n",
      "0029 0021 0.82 [6 5 5 6]\n",
      "0058 0047 0.80 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0280 0303 0.74 [2 3 3 3]\n",
      "0076 0065 0.67 [4 6]\n",
      "0072 0082 0.65 [3 3 1 3 3 3 3 3]\n",
      "0046 0038 0.63 [1 1 1 1]\n",
      "0097 0086 0.60 [6 6 6 6 6 6 6]\n",
      "0038 0031 0.60 [6 5 6 6]\n",
      "0015 0011 0.54 [0 3 3 3]\n",
      "0057 0064 0.50 [6 6 6 5]\n",
      "0076 0070 0.35 [0 5]\n",
      "0146 0154 0.28 [6 6 6]\n",
      "0070 0075 0.24 [5 6 6 6]\n",
      "0111 0106 0.19 [3 0]\n",
      "0151 0145 0.19 [6 6 6 6]\n",
      "0038 0035 0.16 [6 6 5 5]\n",
      "0016 0018 0.14 [5 6 5 6]\n",
      "0133 0129 0.14 [3 3 1 3 3 3]\n",
      "0122 0118 0.14 [1 2]\n",
      "0059 0061 0.07 [4 0]\n",
      "0073 0072 0.05 [5 0]\n",
      "[ 66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131]\n",
      "66 66 66\n",
      "0562 0274 41.39 [3 1 3]\n",
      "0574 0852 27.27 [1 3]\n",
      "0038 0104 17.35 [3 3 3 3 3 3 3 3 3 3]\n",
      "0079 0135 8.00 [3 3 1 3]\n",
      "0052 0022 5.48 [6 6 5 5]\n",
      "0068 0109 5.46 [2 3 2]\n",
      "0130 0083 5.04 [3 0]\n",
      "0069 0036 4.85 [5 4]\n",
      "0051 0085 4.74 [6 5]\n",
      "0030 0055 4.49 [5 5 5 5]\n",
      "0036 0015 4.27 [5 5 5 6]\n",
      "0153 0109 3.74 [3 3 1 3 3 3]\n",
      "0029 0013 2.79 [0 3 3]\n",
      "0038 0058 2.73 [2 3 2 3]\n",
      "0039 0057 2.17 [6 4]\n",
      "0319 0273 2.05 [4 4]\n",
      "2144 2255 1.89 [3 3]\n",
      "0314 0271 1.88 [2 3 3 3]\n",
      "0541 0595 1.70 [3 3 3 3]\n",
      "0083 0063 1.67 [5 6 6 6]\n",
      "0731 0792 1.64 [2 3]\n",
      "0019 0028 1.33 [6 5 6 5]\n",
      "0102 0083 1.26 [3 3 3 3 3 3 1 3]\n",
      "0067 0052 1.18 [5 5]\n",
      "0030 0041 1.09 [6 5 6 6]\n",
      "0046 0035 1.08 [1 1 1 1]\n",
      "0385 0353 1.00 [2 4]\n",
      "0063 0076 0.95 [4 6]\n",
      "0078 0064 0.93 [0 5]\n",
      "0072 0059 0.91 [0 4]\n",
      "0046 0056 0.87 [2 2 2 2]\n",
      "0028 0021 0.78 [5 5 6 5]\n",
      "0063 0052 0.77 [4 0]\n",
      "0269 0249 0.70 [4 2]\n",
      "0084 0095 0.65 [0 3]\n",
      "0078 0069 0.56 [5 0]\n",
      "0071 0080 0.55 [3 3 1 3 3 3 3 3]\n",
      "0026 0031 0.49 [5 6 5]\n",
      "0059 0066 0.48 [6 6 6 5]\n",
      "0425 0406 0.46 [6 6]\n",
      "0038 0033 0.39 [5 6 6 5]\n",
      "0013 0016 0.36 [0 4 1]\n",
      "0153 0144 0.30 [6 6 6 6]\n",
      "0361 0374 0.30 [2 2]\n",
      "0131 0124 0.27 [3 3 3 3 3 3 3]\n",
      "0146 0153 0.25 [6 6 6]\n",
      "0028 0025 0.22 [6 5 5 5]\n",
      "0298 0306 0.19 [4 3]\n",
      "0160 0155 0.17 [5 6]\n",
      "0092 0089 0.12 [6 6 6 6 6 6 6]\n",
      "0015 0016 0.07 [0 3 3 3]\n",
      "0035 0034 0.06 [6 6 5 6]\n",
      "0205 0206 0.04 [3 3 1 3 3]\n",
      "0052 0052 0.01 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0026 0026 0.01 [6 5 5 6]\n",
      "[ 66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 66 66\n",
      "0932 0625 26.86 [1 3]\n",
      "0075 0022 12.22 [5 5 5 5]\n",
      "0064 0127 11.23 [3 3 3 3 3 3 1 3]\n",
      "0107 0046 10.36 [3 3 3 3 3 3 3 3 3 3]\n",
      "0884 0710 9.06 [2 3]\n",
      "0362 0263 7.48 [4 4]\n",
      "0122 0070 6.41 [6 6 6 6 6 6 6]\n",
      "0370 0277 6.37 [4 3]\n",
      "2423 2207 5.51 [3 3]\n",
      "0139 0088 5.49 [3 0]\n",
      "0639 0531 5.07 [3 3 3 3]\n",
      "0155 0109 4.03 [1 2]\n",
      "0098 0065 3.47 [3 3 1 3 3 3 3 3]\n",
      "0062 0037 3.16 [2 3 2 3]\n",
      "0020 0037 2.91 [5 5 5 6]\n",
      "0154 0117 2.78 [3 3 1 3 3 3]\n",
      "0019 0034 2.73 [6 5 5 6]\n",
      "0049 0072 2.61 [5 5]\n",
      "0020 0034 2.24 [0 3 3]\n",
      "0062 0042 2.12 [6 4]\n",
      "0084 0064 1.69 [4 6]\n",
      "0405 0362 1.59 [2 4]\n",
      "0175 0147 1.57 [6 6 6]\n",
      "0370 0413 1.56 [2 2]\n",
      "0046 0033 1.35 [6 6 5 5]\n",
      "0152 0175 1.19 [5 6]\n",
      "0458 0420 1.16 [6 6]\n",
      "0061 0047 1.11 [2 2 2 2]\n",
      "0086 0101 0.93 [0 3]\n",
      "0164 0144 0.92 [6 6 6 6]\n",
      "0048 0059 0.91 [5 4]\n",
      "0042 0033 0.82 [6 6 5 6]\n",
      "0010 0015 0.72 [0 4 1]\n",
      "0031 0039 0.67 [5 6 6 5]\n",
      "0048 0040 0.64 [1 1 1 1]\n",
      "0082 0071 0.62 [5 0]\n",
      "0074 0064 0.58 [0 4]\n",
      "0028 0023 0.52 [6 5 6 5]\n",
      "0129 0139 0.41 [3 3 3 3 3 3 3]\n",
      "0075 0068 0.38 [6 5]\n",
      "0074 0079 0.24 [5 6 6 6]\n",
      "0220 0227 0.21 [3 3 1 3 3]\n",
      "0303 0311 0.20 [2 3 3 3]\n",
      "0063 0067 0.17 [6 6 6 5]\n",
      "0056 0053 0.17 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0075 0072 0.13 [0 5]\n",
      "0038 0036 0.12 [6 5 6 6]\n",
      "0025 0024 0.11 [6 5 5 5]\n",
      "0062 0064 0.10 [4 0]\n",
      "0032 0033 0.09 [5 6 5]\n",
      "0099 0097 0.07 [2 3 2]\n",
      "0026 0027 0.07 [5 5 6 5]\n",
      "0273 0276 0.07 [4 2]\n",
      "0450 0453 0.05 [3 1 3]\n",
      "[ 66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131]\n",
      "66 66 66\n",
      "0096 0205 21.46 [6 6 6]\n",
      "0276 0146 17.28 [3 3 1 3 3]\n",
      "0206 0099 16.26 [6 6 6 6]\n",
      "0507 0339 14.97 [6 6]\n",
      "0024 0069 13.21 [2 3 2 3]\n",
      "0092 0035 10.91 [6 6 6 5]\n",
      "0078 0027 10.45 [2 2 2 2]\n",
      "0650 0503 8.82 [3 3 3 3]\n",
      "0012 0039 8.61 [5 5 6 5]\n",
      "0021 0053 7.95 [6 6 5 5]\n",
      "0348 0252 7.34 [4 4]\n",
      "2109 2327 5.98 [3 3]\n",
      "0191 0131 5.33 [5 6]\n",
      "0222 0293 5.31 [4 2]\n",
      "0010 0028 5.13 [5 6 5 6]\n",
      "0668 0784 4.97 [1 3]\n",
      "0467 0381 4.49 [3 1 3]\n",
      "0111 0070 4.47 [2 3 2]\n",
      "0095 0137 4.17 [1 2]\n",
      "0055 0087 4.13 [6 5]\n",
      "0030 0052 3.70 [1 1 1 1]\n",
      "0078 0112 3.61 [3 3 3 3 3 3 1 3]\n",
      "0033 0015 3.39 [6 5 5 6]\n",
      "0090 0124 3.19 [3 3 1 3]\n",
      "0035 0017 3.15 [5 6 5]\n",
      "0059 0085 2.80 [3 3 3 3 3 3 3 3 3 3]\n",
      "0146 0110 2.77 [3 3 3 3 3 3 3]\n",
      "0082 0056 2.73 [4 6]\n",
      "0105 0077 2.40 [6 6 6 6 6 6 6]\n",
      "0031 0017 2.34 [6 5 6 5]\n",
      "0810 0743 1.82 [2 3]\n",
      "0053 0036 1.82 [5 5 5 5]\n",
      "0116 0144 1.81 [3 3 1 3 3 3]\n",
      "0021 0032 1.67 [5 5 5 6]\n",
      "0084 0065 1.46 [5 0]\n",
      "0043 0058 1.44 [5 4]\n",
      "0076 0059 1.36 [0 4]\n",
      "0390 0352 1.35 [2 4]\n",
      "0021 0029 1.07 [6 5 5 5]\n",
      "0309 0280 1.05 [2 3 3 3]\n",
      "0084 0072 0.81 [3 3 1 3 3 3 3 3]\n",
      "0048 0057 0.68 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0369 0393 0.65 [2 2]\n",
      "0087 0098 0.61 [0 3]\n",
      "0038 0032 0.50 [6 6 5 6]\n",
      "0064 0056 0.49 [5 5]\n",
      "0310 0293 0.47 [4 3]\n",
      "0012 0015 0.46 [0 4 1]\n",
      "0077 0069 0.46 [0 5]\n",
      "0113 0108 0.21 [3 0]\n",
      "0061 0058 0.18 [4 0]\n",
      "0071 0074 0.10 [5 6 6 6]\n",
      "0035 0036 0.07 [5 6 6 5]\n",
      "0049 0048 0.06 [6 4]\n",
      "0036 0035 0.05 [6 5 6 6]\n",
      "[ 66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131]\n",
      "66 66 66\n",
      "0208 0352 18.87 [4 4]\n",
      "0018 0067 17.51 [5 5 5 5]\n",
      "0439 0623 16.09 [3 3 3 3]\n",
      "0016 0050 10.39 [5 6 6 5]\n",
      "0409 0295 8.72 [2 2]\n",
      "0146 0082 8.06 [1 2]\n",
      "0020 0049 7.05 [6 6 5 5]\n",
      "0013 0037 6.81 [6 5 5 6]\n",
      "0239 0322 6.54 [4 3]\n",
      "0064 0107 6.05 [2 3 2]\n",
      "0066 0032 5.61 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0309 0390 5.08 [2 4]\n",
      "0066 0105 5.06 [6 6 6 6 6 6 6]\n",
      "0114 0164 5.00 [6 6 6 6]\n",
      "0085 0048 4.88 [5 6 6 6]\n",
      "0241 0308 4.46 [2 3 3 3]\n",
      "0098 0139 4.06 [3 3 1 3 3 3]\n",
      "0023 0044 4.01 [6 5 6 6]\n",
      "0036 0062 3.92 [2 2 2 2]\n",
      "0014 0031 3.81 [0 3 3]\n",
      "0355 0426 3.71 [6 6]\n",
      "0105 0070 3.64 [3 3 3 3 3 3 1 3]\n",
      "1975 2122 3.18 [3 3]\n",
      "0054 0079 2.84 [3 3 3 3 3 3 3 3 3 3]\n",
      "0055 0034 2.63 [2 3 2 3]\n",
      "0636 0702 2.06 [1 3]\n",
      "0216 0183 1.69 [3 3 1 3 3]\n",
      "0054 0071 1.66 [0 4]\n",
      "0048 0064 1.54 [4 0]\n",
      "0684 0739 1.46 [2 3]\n",
      "0038 0026 1.31 [6 6 5 6]\n",
      "0027 0018 1.22 [5 5 6 5]\n",
      "0062 0077 1.20 [5 0]\n",
      "0020 0028 1.13 [6 5 5 5]\n",
      "0077 0093 1.11 [0 3]\n",
      "0027 0019 1.00 [5 5 5 6]\n",
      "0128 0113 0.82 [3 3 3 3 3 3 3]\n",
      "0060 0071 0.76 [0 5]\n",
      "0050 0041 0.75 [6 4]\n",
      "0055 0065 0.70 [6 6 6 5]\n",
      "0033 0026 0.68 [5 6 5]\n",
      "0252 0233 0.67 [4 2]\n",
      "0142 0156 0.61 [5 6]\n",
      "0058 0067 0.56 [4 6]\n",
      "0035 0042 0.55 [1 1 1 1]\n",
      "0096 0107 0.53 [3 0]\n",
      "0384 0401 0.41 [3 1 3]\n",
      "0147 0139 0.32 [6 6 6]\n",
      "0061 0057 0.23 [5 5]\n",
      "0011 0013 0.17 [0 4 1]\n",
      "0015 0016 0.12 [5 6 5 6]\n",
      "0046 0048 0.12 [5 4]\n",
      "0065 0067 0.10 [6 5]\n",
      "0074 0072 0.06 [3 3 1 3 3 3 3 3]\n",
      "[ 66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131]\n",
      "66 66 66\n",
      "0418 0696 35.23 [3 3 3 3]\n",
      "0232 0338 10.17 [4 4]\n",
      "0242 0345 9.35 [4 3]\n",
      "0357 0461 7.04 [3 1 3]\n",
      "0054 0023 5.68 [1 1 1 1]\n",
      "0172 0233 5.08 [3 3 1 3 3]\n",
      "0404 0320 4.94 [2 2]\n",
      "0015 0035 4.63 [0 3 3]\n",
      "0102 0147 4.48 [3 3 1 3 3 3]\n",
      "0127 0176 4.46 [5 6]\n",
      "0028 0010 3.86 [5 6 5 6]\n",
      "0030 0053 3.68 [5 5 5 5]\n",
      "0087 0121 3.28 [3 0]\n",
      "0015 0030 2.86 [6 5 6 5]\n",
      "0130 0096 2.75 [1 2]\n",
      "0114 0086 2.26 [3 3 1 3]\n",
      "0055 0036 2.24 [6 4]\n",
      "0068 0047 2.17 [5 5]\n",
      "0330 0380 2.17 [2 4]\n",
      "0059 0079 1.87 [0 5]\n",
      "0050 0067 1.73 [6 6 6 5]\n",
      "0735 0676 1.60 [1 3]\n",
      "0079 0099 1.58 [3 3 3 3 3 3 1 3]\n",
      "0131 0156 1.50 [6 6 6 6]\n",
      "0059 0076 1.49 [6 5]\n",
      "0061 0078 1.46 [3 3 3 3 3 3 3 3 3 3]\n",
      "0041 0028 1.44 [6 6 5 6]\n",
      "0029 0019 1.33 [6 5 5 5]\n",
      "0030 0019 1.33 [5 5 6 5]\n",
      "0113 0133 1.21 [3 3 3 3 3 3 3]\n",
      "0055 0044 0.97 [5 4]\n",
      "0064 0077 0.92 [5 0]\n",
      "0049 0039 0.86 [2 3 2 3]\n",
      "2109 2174 0.86 [3 3]\n",
      "0058 0068 0.78 [0 4]\n",
      "0729 0763 0.70 [2 3]\n",
      "0270 0291 0.67 [2 3 3 3]\n",
      "0079 0069 0.61 [3 3 1 3 3 3 3 3]\n",
      "0260 0244 0.48 [4 2]\n",
      "0022 0027 0.43 [6 5 5 6]\n",
      "0085 0093 0.40 [2 3 2]\n",
      "0031 0036 0.35 [5 6 6 5]\n",
      "0033 0038 0.35 [6 6 5 5]\n",
      "0052 0047 0.34 [2 2 2 2]\n",
      "0085 0091 0.29 [6 6 6 6 6 6 6]\n",
      "0068 0063 0.28 [4 6]\n",
      "0069 0072 0.17 [5 6 6 6]\n",
      "0087 0090 0.16 [0 3]\n",
      "0052 0049 0.14 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0026 0027 0.12 [5 6 5]\n",
      "0150 0146 0.11 [6 6 6]\n",
      "0058 0056 0.08 [4 0]\n",
      "0399 0403 0.07 [6 6]\n",
      "0034 0033 0.02 [6 5 6 6]\n",
      "0025 0025 0.02 [5 5 5 6]\n",
      "[ 66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131]\n",
      "66 66 66\n",
      "0275 0528 41.28 [3 1 3]\n",
      "0102 0200 17.09 [6 6 6]\n",
      "0830 0614 14.87 [2 3]\n",
      "0081 0160 13.83 [3 3 1 3 3 3]\n",
      "0785 0583 13.80 [1 3]\n",
      "0025 0057 7.65 [5 5 5 5]\n",
      "0235 0317 6.38 [2 3 3 3]\n",
      "0013 0035 5.97 [6 5 5 5]\n",
      "0142 0089 5.71 [1 2]\n",
      "0014 0036 5.61 [5 5 5 6]\n",
      "0068 0107 4.98 [6 6 6 6 6 6 6]\n",
      "0084 0047 4.98 [4 6]\n",
      "0324 0251 4.69 [4 3]\n",
      "0015 0035 4.59 [6 5 5 6]\n",
      "0584 0490 4.29 [3 3 3 3]\n",
      "0015 0033 4.17 [5 5 6 5]\n",
      "0143 0099 4.12 [3 3 3 3 3 3 3]\n",
      "0311 0246 3.94 [4 4]\n",
      "0070 0041 3.80 [5 5]\n",
      "0032 0055 3.43 [2 3 2 3]\n",
      "0025 0044 3.37 [6 6 5 6]\n",
      "0053 0080 3.18 [6 5]\n",
      "0035 0018 2.85 [0 3 3]\n",
      "0046 0068 2.70 [4 0]\n",
      "0061 0087 2.65 [3 3 1 3 3 3 3 3]\n",
      "2159 2027 2.57 [3 3]\n",
      "0152 0117 2.53 [6 6 6 6]\n",
      "0056 0035 2.48 [6 4]\n",
      "0218 0176 2.48 [3 3 1 3 3]\n",
      "0017 0030 2.39 [6 5 6 5]\n",
      "0071 0096 2.24 [0 3]\n",
      "0053 0073 2.18 [0 4]\n",
      "0059 0040 2.00 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0136 0167 1.98 [5 6]\n",
      "0026 0039 1.79 [5 6 6 5]\n",
      "0067 0049 1.75 [6 6 6 5]\n",
      "0265 0230 1.61 [4 2]\n",
      "0096 0078 1.27 [3 3 3 3 3 3 1 3]\n",
      "0371 0336 1.18 [2 2]\n",
      "0075 0060 1.12 [5 6 6 6]\n",
      "0029 0020 0.99 [5 6 5]\n",
      "0031 0040 0.91 [6 6 5 5]\n",
      "0043 0054 0.87 [2 2 2 2]\n",
      "0072 0061 0.76 [0 5]\n",
      "0106 0093 0.70 [3 3 1 3]\n",
      "0014 0019 0.65 [5 6 5 6]\n",
      "0072 0063 0.56 [3 3 3 3 3 3 3 3 3 3]\n",
      "0354 0336 0.49 [2 4]\n",
      "0107 0098 0.44 [3 0]\n",
      "0399 0384 0.35 [6 6]\n",
      "0050 0046 0.26 [5 4]\n",
      "0085 0090 0.22 [2 3 2]\n",
      "0034 0031 0.21 [6 5 6 6]\n",
      "0067 0070 0.11 [5 0]\n",
      "0013 0013 0.01 [0 4 1]\n"
     ]
    }
   ],
   "source": [
    "niter = 10\n",
    "\n",
    "m2lnLR_explos = np.zeros((niter,len(w_dict_explo)))\n",
    "emps_explos = np.zeros((niter,len(w_dict_explo)))\n",
    "exps_explos = np.zeros((niter,len(w_dict_explo)))\n",
    "\n",
    "for n_ in range(niter):\n",
    "    L = len(data_explo_hmm)/2\n",
    "\n",
    "    length_per_traj = len(data_explo_hmm)/len(lengths_explo_hmm)\n",
    "    numtrajs = int(L/length_per_traj)\n",
    "\n",
    "    sample_lengths = np.random.choice(len(lengths_explo_hmm),numtrajs, replace=False)\n",
    "    nonsample_lengths = np.delete(np.arange(len(lengths_explo_hmm)),sample_lengths)\n",
    "\n",
    "    lengths_explo_train = lengths_explo_hmm[sample_lengths]\n",
    "    for i,l in enumerate(sample_lengths):\n",
    "        first = np.sum(lengths_explo_hmm[:l])\n",
    "        last = np.sum(lengths_explo_hmm[:l+1])\n",
    "        if i==0:\n",
    "            data_explo_train = data_explo_hmm[first:last]\n",
    "        else:\n",
    "            data_explo_train = np.concatenate((data_explo_train, data_explo_hmm[first:last]))\n",
    "\n",
    "\n",
    "    lengths_explo_test = lengths_explo_hmm[nonsample_lengths]\n",
    "    for i,l in enumerate(nonsample_lengths):\n",
    "        first = np.sum(lengths_explo_hmm[:l])\n",
    "        last = np.sum(lengths_explo_hmm[:l+1])\n",
    "        if i==0:\n",
    "            data_explo_test = data_explo_hmm[first:last]\n",
    "        else:\n",
    "            data_explo_test = np.concatenate((data_explo_test, data_explo_hmm[first:last]))\n",
    "\n",
    "    Hexplo_train =  -model_fit.score(data_explo_train,0)/len(data_explo_train) \n",
    "    Hexplo_test =  -model_fit.score(data_explo_test,0)/len(data_explo_test) \n",
    "    Yexplo_train = np.exp(model_fit._compute_log_likelihood(data_explo_train) + Hexplo_train)\n",
    "    Yexplo_test = np.exp(model_fit._compute_log_likelihood(data_explo_test) + Hexplo_test)\n",
    "\n",
    "    m2lnLR_explo,emps_explo,exps_explo = compare_datasets(Yexplo_train, lengths_explo_train, Yexplo_test, lengths_explo_test, w_dict_explo, w_dict_explo, params,model_fit)\n",
    "    \n",
    "    m2lnLR_explos[n_] = m2lnLR_explo\n",
    "    emps_explos[n_] = emps_explo\n",
    "    exps_explos[n_] = exps_explo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the false positives vs threshold on score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAADqCAYAAADtRfPYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XtwVHf5+PH3kw1tYUMJ6a8qDnZyQct0mA7JhjLqYC8EaLRo0xYoY+3YG+lFa2d+SlovNBYVwZ86HbFfE5w6dZyBFrQUMoMp8C1Mqw4tEGYqtLWSYC8yzggEmwiUbJ7fH+dsONlsks3J7p69PK+ZnbDnnN39wMLD5/Ocz+f5iKpijDFBKQq6AcaYwmZByBgTKAtCxphAWRAyxgTKgpAxJlAWhIwxgbIgZIwJlAUhY0ygioNuQLqIyMXAHOA4EA24OcYUmhAwDXhNVc+NdGHeBiGcAPRy0I0wpsDNA14Z6YJ8DkLHAV5++WWmT58edFuMKSjvvfce8+bNA/ff4UjyOQhFAaZPn055eXnATTGmYI2aCrHEtDEmUBaEjDGBsiBkjAmUBSFjTKAKNgg1NzcjIsM+mpubg26iMQVB8rWyooiUA11dXV2j3h277rrrANizZ096G2VMgTh27BgVFRUAFap6bKRrC7YnZIzJDhaEjDGBsiBkjAmUBSFjTKAsCBljAmVByBgTqIIPQtFolBMnTvCPf/yDtrY2olErPWRMJhV0EIpGoyxatIgjR45w7Ngxli9fzqJFiywQGZNBgZfyEJHbgEr3aRVwQFVb466pAeqATqAM6FTVXeP97B07dvCXv/yF/v5+AHp6eti3bx87duzgpptuGu/bG2OSEGgQcgPQQVXd4jl2QERKVXWd+7wSeExVl3iu2SwiJ1X14Hg+v6OjgzNnzgw61tvby6FDhywIGZMhQQ/HHgMa447tijvWBLTEXbMGWDveD6+uriYcDg86Fg6HmT179njf2hiTpKCDUBPwbNyxUpxhV8zSuOe4z+vG++H19fXMnTsXEQGgpKSEuXPnUl9fP963NsYkKdAgpKq7vEMqESnFCTpN7vNKoFRVO+Ne1+2er4l/TxFZISL7gW2jfX4oFKK9vZ2Pf/zjAKxbt4729nZCodA4flfGmLEIPDENICJ1QA1wGRDxBJ3SUV5aFn/ATWq3xlbRj/bZoVCIj33sY7z//vtceumlFoCMybCgh2PAQI9oHfAa0OT2iDImHA5TVFTEgQMHMvmxxhiyJAjFuHfJjgK7vcfTHZREhHA4zP79+9P5McaYBLIqCLl2ATVuvqfbPTZo2OUJSidT9aGTJ0+mo6PDJioak2GBBSERqRSRU27y2SsWeCrd3FA3Q3NDZQDjnSfkNXnyZHp6evjb3/6Wqrc0xiQhyJ5QKbCfob2ZWFCKBZhdnmPea8Y9Y9pr8uTJAJYXMibDfAUhESkXkdlxx74pIs+KyD3JvIfbi9mZ4FQT0Oq5Q9aEM6nRq9E97pu30P3evXsH8kFf+cpXrNC9MRnkq9C9iDwLnFTVB9znLwLzgQ6gGlirqt9O8r1W4KwZO+H+PBpbsuG5pg6n99MZ+zna2rGxFLqP+cxnPkMoFOLll19O6npjTGJjKXTvd57QAuBeABGpxpm9vFJV/58bVL4FJBWE4herDnNNSodew6mtreXpp58mGo3afCFjMsRvTsi7tKIOUCC2CPUoQ3M4OSESidDb28tbb70VdFOMKRh+g1AnsFRELgWW4ayEP+aeiw2bck5tbS1gyWljMslvEHrUfZzCWW7hTRI3cqFXlFNmzpzJpEmTbNKiMRnkKyekqltEZAZOEnqXqp72nG4hxbfPMyUUClFdXW09IWMyaDzzhP4NVADPusMyRGQKTs/oRAraFohIJGIzp43JIL/zhKpxhmK349wpA8DtEVUBP05J6wJQW1vLf//7X958882gm2JMQfDbE2rFmVBYC0iCc8vG1aoARSIRAMsLGZMhfoNQBNg8zLlTjF4HKGtdeeWVhMNhywsZkyF+g9BBnKR0Io3kaGIaLDltTKb5nTH9Y5yEtOBMVJwa2xUDuBWnp5SzamtraWlpoa+vj+LirCg+aUze8tUTcouPPQasw8kJdeL0jiLAQlU9lLIWBiASiXDmzBlLThuTAb5v0buLTKfi3B1bClSp6gxV3T3yK7OfJaeNyRy/t+gvBeeWvKruVtXfq+qoReVzxac+9SlKSkosL2RMBvjtCXWLyKsick8sIOWTWHLaekLGpJ/fIHS/+9oNwCkRaReRhtQ1K3i1tbUcOnSIvr6+oJtiTF7zm5iOTVScipOgvgz4vYhE3eqKOR+QIpEIZ8+e5ciRI0E3xZi8Nq4a025OaJ2q1qpqEW6CmhxdRe9lZT2MyYyUFLoXkVvckq+tOAtYO1LxvkH65Cc/yeTJky0IGZNmvoNQLPCISBSn5xPBmcRY5Q7VclpRURE1NTWWnDYmzXxNBxaRfpyZ0qeBnwDPqmrO937iRSIRnnrqKc6fP8+ECROCbo4xeWk8q+hrVbVMVR/NxwAETl7IktPGpJffu2P352vg8YrNnLa8kDHpk4170WeNGTNmMHnyZMsLGZNGSeWE3OTzZlW93X1+EicnNBxV1f+TgvYFqqioiEgkYj0hY9Io2cT0HwDvwtQNjByE8kYkEmH9+vWWnDYmTZIKQqq6JO75uPaBzyW1tbWcO3eOw4cPM3v27KCbY0zesZzQKCw5bUx6+S3l8baIlA9z7jkR+dF4GpVNqqqqmDJliiWnjUkTvz2hqhHOtQBLRjifU2Izp60nZEx6JD1j2q0b5F2OMV9E4guZleIUuq9MQduyRm1tLU8++SQffvghF110UdDNMSavjGXZxjKcXg44d8Y2jHDtOt8tykKRSIQPP/yQw4cPU1093CYjxhg/kh6OqeoGnPpBZTjF7RfgDMu8j6mqWqSqj6ahrYGJlfWwvJAxqTemBazuNs+IyBbgNVX9z3gbICK34QS2CM4wrsXdzcN7TQ1Qh7OrRxnQqaoZ29ussrKS0tJSDhw4wH333ZepjzWmIPhdO7Y0hQHooFupsREnob1WRFZ6rqkEHnOLp21R1Vag0Q1Madfc3ExRURHd3d20tLQgIoMezc3NmWiGMXkrqSDklm3d5Hl+UkROjPD4d5KfX6aqnbEnqtoNNAFrPdc0cSEXFbMm7pq0aW5uRlVZuXIlIsK8efNQ1YGHBSFjxiewZRtuD6dFRPar6kHPqYPu+Rr3+FKGBpxOnOFZxkQiEVSV3t7eTH6sMXkvsGUbqtopIutwAopXqfuz0w1Upd7ekvvabnc4VBMXwNImlpz+4IMPMvFxxhQMvzOmy0Vkdtyxb7rlXu9J9n1Utckdgnktw8kTdXMhIA2nLEHbVojIfmBbsu1IxhVXXEFRURHHjx+nra2NaDSayrc3pmD5nTG9DmdSIgAi8iLOkKkKaPW7bENESoEVjGPGtWc7oi/6fY940WiUG2+8kf7+fnp6eli+fDmLFi2yQGRMCvgNQnXATgARqXafN7n/+B/AfxDZDCyJH365wSkwO3bsYN++fQPPe3p62LdvHzt27AiwVcbkB79BqJQLuZw6nCR1bG7PUXws2xCRtcDauPk/saFaWdy1saB0cqyf40dHR8eQhHRvby+HDh3KxMcbk9f8BqFOYKm7niyWwznmnqtkaLJ5RCKyAtgZPwHR7RElyg2VueczkpSurq4mHA4POhYOh62+kDEp4DcIPeo+TuFsdui9W9bIGHZgdScsDpoBLSI17p0xgF0M7VlVusczor6+nrlz51JUdOGPa86cOdTX12eqCcbkLb8zprcAM3Dm8ExV1f/1nG5h6OTChESkDncZhohUuo8aoNGTF2rC2e/eq5HBgS+tQqEQ7e3tXHXVVVx++eUAfPvb3yYUCmWqCcbkLV+bH8LAPJ9LgUfdwNEJPOcudB2Vm9fZOcxp7yzqThFpcodsnVxYX5aRoVhMKBTisssuo7S0lA8++IBt27ZRV5fR+ZLG5CXfQUhE/genR9KNExzmACtEZGBXjpG484Akmc/K5GLV0YRCIRYuXMjWrVt58sknEUnqt2CMGYbfyYr34SSkF7i7sNaqapl7bKmI/N9UNjLbNDQ08O6771q1RWNSwG9iegWwUlW968liuaJHgfvH27Bs0dzcPLBifu/evezdu5e77roLcJLTtoDVmPER1bGvQxWRfqAuLiEdOzcfeFFVA83auoX4u7q6uigvL0/5+8+fP5/jx4/bPvXGJHDs2DEqKioAKjzTdxLy2xPaxfCr2JfgroTPZw0NDbzxxhu89dZbQTfFmJw2rnlCIvIjdzHrpSIy201W30cGb58H5eabbwbg+eefD7glxuQ2v/OEYnV+7sdZpnEKOICbmE40TMs306dPZ86cORaEjBkn3zuwuqVWy4BFOMFoIc747/epaly2a2ho4NVXX+X9998PuinG5KxxbwOtqrtUdYOq7o4Vwi8UDQ0NAGzdujXglhiTu3wHITcX9D8i8pq7LXS7myO6NJUNzGYzZ85k5syZNiQzZhz8Tlacj5MLasSZ9dwBXIaTsO4cbp/6fNTQ0MCePXs4ceJE0E0xJif57Qm1AKeBiDtbeqlb0KzWfc9fpaqB2a6hoYFoNEpbW1vQTTEmJ/kNQmU4M6Y7vAfdu2aP4uzOWhBqa2uZPn26DcmM8clvEBppP+SjOMOzgiAi3HzzzbS3t9t2QMb44DcINeEpdB9npfsoGA0NDZw9e5b29vagm2JMzvEbhDYAEXdn1kEPnKHYzrjjfalrcvb53Oc+R1lZmQ3JjPHBbz2hFpztfQxQXFzM4sWLeeGFFzh//jwTJkwIuknG5AxfQSjZ6omFpKGhgWeeeYY9e/awYEHB5OWNGbdxz5g2joULFzJp0iQbkhkzRhaEUmTixInU19ezdetW+vv7g26OMTnDglAKNTQ0cPz4cV599dWgm2JMzrAglEJf+MIXKC4utiGZMWNgQSiFSktLueGGG3j++efxUzbXmEJkQSjFGhoaePvtt632tDFJsiCUQs3NzTzwwAMAzJo1a2CXjtjDduYwZqjx1BO6VES+6dYRutQ9NsWtMVQwNYW8mpubUVU+/elPU1JSwrXXXouqDjwsCBkzlN96QtU4daVvx7PrhltZsQr4cUpal6O+9KUv0dPTw9GjR2lrayMajQbdJGOylt+eUCvQ6tYQit8HuRWn4H1BikajvPDCCwC89957LF++nEWLFlkgMmYYfoNQBNg8zLlTQKnP9815O3bs4PXXXx943tPTw759+9ixY0eArTIme/kNQgeB6mHONeJsjliQOjo6htQV6u3t5dChQwG1yJjs5ncV/Y+BZ0VEAAWmikgl8BhwK05PqSBVV1cTDofp6ekZOHbxxRcze/bsAFtlTPbyu/nhFpyAsw4nJ9SJ0zuKAAtVtWD/26+vr2fu3LkUFTl/tCJCf38/11xzTcAtMyY7jWfzw3XAVJwiZkuBKlWdoaq7U9W4XBQKhWhvb+eqq66ivLycn//85/T39/PQQw/ZLGpjEvB7i75cRGar6ml308PfA7eKyLMico+P91srIjXDnKsRkZUicpuIrBCRukTXZYPm5mZEhOLiYv76179y7NgxHnnkEfr6+tiyZQu33HJL0E00Juv47QmtxVNjWkTa3WNVQKuI/Gi0NxCRShFpEZG1wAqcHTyGXAM8pqrr3G2nW4HG4QJW0GKTFeMffX19zJs3j927d9PV1RV0M43JKn6D0AJgJwxMXFwANLnzhh4Aloz2BqraqaqNqtoEnBzmsiacUrJea3ACXs4IhUL89re/RUS48847bc6QMR5+g1ApTjIanBnTCmxxnx8FKsfZrpilns+J6cQzSztXlJeXs379el555RV+8pOfBN0cY7KG3yDUCSx114gtAw6q6jH3XCVDA8eYuUOxUlUd9F6q2u2ez8oh2UjuuOMOlixZwve+9z0OHjwYdHOMyQp+g9Cj7uMUUIMzbIpp5EKvaDxGm3U9JIcE4Cav9wPbUtCGlBIRfvWrX/GRj3yEO+64gzNnzgTdJGMCN555QjNwhktTVfV/PadbcNaPBUJVY2vavhhUG0ZSVlbGM888wxtvvEFTU9PoLzAmz41nnlCnqv7eXTnvPb5BVVN2C0hE8m4dWl1dHd/4xjf4xS9+Ybu2moI3ahASkZMicmKMj3+noG3d7s9Bwy5PUBrujlpOCIfDANx4441Dip9ZATRTSJJZO7YB5+5XRqlqp4h0MzQ3VOaez+nM7g9/+ENuvfVWamtrB2ZSl5SUMHfuXNrb2wmFQgG30JjMGDUIufN4grIL526bN+BUkier9P/5z38yYcIEPvzwQ2Bw2Y+bbrop4NYZkxnZXmO6CWehrFcjg+/G5ayOjg7Onz8/6JiV/TCFxm8pDwBE5AYST0w8qap/GOW1pTgBptJ9rBWRXcBOVd0FA0OyJhFZgTP3qBJoyfWhWEyish9wIV9kTCHwFYREpALYj7OKHpyckXh+3QmMGITcSYej9mhiASkfxcp+vPTSS/T39zNx4kT6+/tpampi8uTJ3HvvvUE30Zi08zscawEO4CxYLcMJQKXurzvIsbVdQWhubqa4uJjdu3cP7F1/5swZzp07x/nz57nvvvu45557bEKjyXt+g1AdsFJVu9weTSdQ6endNI74ajPsivvYqvvvfve7PP3003z2s5+1lfcmr/kNQt1Ahef5QaDW/XUpzlIO41MoFGL16tVs27aNI0eOUFlZmXAukc0nMvnAbxDaBSz0PH8OaBKRW3CSzd0JX2XGZPHixRw+fJirr74acNaegTOfaP78+fT19VkQMjnPbxBqAgaWa7hryY7hLFytBO4bd8sMAFVVVaxatYri4uKBSY22jZDJJ34XsHap6qNxxxbg1JkuG+32vBmbI0eODCmE1tPTw7ZtWVcowJgxS2bt2GvufKBRpXLhqrkgNp8o3oYNG7j++uvZuXOnFdE3OSuZnlCEBLV9RKRaRKxOaQbEbyNUUlLCddddx09/+lPefvttFi5cyDXXXMOyZcuGTWBbEttkreFuE8ceQD9wS4Lj1UB0tNcH9QDKAe3q6tJ80NfXp7NmzdLy8nLdvn279vX1qarq2bNndcOGDVpVVaWAzpw5U6+66iotKipSQEtKSnT+/PkD1xuTCV1dXYozcblcR/m3mu1rxwpeom2EFi9eTHFxMSLCmjVruPfee3nzzTfZuHEjZ86c4ciRIwMTIC2JbbKdBaEsN9KkRlUdGGIVFxdz++23c/fddw/cyo/p7e21mtYmayUbhGzeT46oqakZksRWVTZs2MDmzZsHekjGZItkF7De5u5+4VUF4O64KvEvUNVfj7Ntxof4RbElJSVUVFTQ19fH0qVLmT17Nj/4wQ/4/Oc/P6THZEwgRksa4SSmx/oIPGFNniWmk/H444/HkoEJHw0NDVpZWamATp8+fcRrH3/88aB/OyaHjSUxLTrK/BIRme8zuO3287pUEZFyoKurq4vy8vIgm5JVzp8/z29+8xueeOIJ3n//faZOncrp06cHek1WXtakwrFjx6ioqACo0At7EiY0ahDKVRaERnb27Fm+/vWv8+tfDx41T5w4kU2bNvHFL2bljkkmR4wlCNndsQJ1ySWXcMUVVwzJC505c4Yvf/nLNDY20tbWNlDPKBqN0tbWxurVq2lraxuyjMQYv8ZV3tXktkTlZS+++GKuvvpqNm7cSGtrK8XFxfT19Q37Ho8//rjNxDbjYj2hAtXc3MzixYuH1Lc+d+4cf/7zn3n44Ydpb2/n/vvv5/LLLx/y+nA4zPbt2y0AmXGznFCBi0aj7Nixg0OHDjF79mzq6+uHJKWfeOKJgUmTXg0NDWzatImLLrook002OWAsOSEbjhW4UCjETTfdNOI+Z7EJkN5eU1FREc8//zwzZszgW9/6Fvfccw+TJk3KRJNNnrHhmBnRcMO22MxrEeHhhx+mvLycNWvWcPr0aUtimzGx4ZhJykjDtpdffpk1a9aMukjWktiFw+YJYUEoCB0dHTz88MO88sorg45fcsklPPXUU3z1q18dMiUgFtw6Ojqorq5OmJMyucdyQiYQ1dXVLFy4kD/96U+Dkthnz57l7rvv5pFHHmHWrFnMmjWLd955hz/+8Y/Dvld8r8mCVf6yIGRSKtHco4kTJ3LXXXdRVFTE66+/zpYtWzh58mTC10+YMIEHH3yQG264gXfffZcNGzawevXqYT8v0RBvLAHLglsWGG1xWa4+KMAFrEEbbQFtbFFsf3+/Hj9+XO+8884Rrwd0woQJOm3aNA2FQoOOX3zxxbpy5Upta2vTl156SV999VV98MEHR3yvVatWaX9/v/b39+uqVavGtIC3r69Pt2/frk888cSgypaJjOXafJXSBay5ynJCwUlm7hFAW1sby5cvH9RrCofD/OxnP6OiooKuri46Oztpa2vj8OHDGWl7KBTi5ptvZsGCBVRUVLB9+3bWr18/7PXenlhzczPf//73k7o2JtmeWLp6d+nqCVpiGgtC2W4s/2ATBatJkyaxbt065syZQ29v78Bj06ZNbN26dcj7XX/99Vx77bWDju3du5eXXnppyLVFRUVDir+JyKA8V3FxMddeey2f+MQnBl337rvvsnfv3kFLXSZMmMCyZcuora0lHA4TDofZtm0bmzZtGvb3/9BDD/G1r32N9evX88tf/nLY61atWjXw5ziWP9N0BkywIARYEMoVo/WaxvqPJVHAKikpYePGjUMmZA537e9+9ztqamro7Oykq6uLZ555hj179gz57ClTpjBlypRBx06fPs3p06eHXJsuRUVFA4EtHA4TjUZ55513BgXRUChEJBLhox/96KDX/utf/+LAgQOD5nEVFxezePFirr76akpKSgiHw7z44osJA3tMooA1liAUeO4mXQ8sJ5RXYnmW1atXD5tnSTYnNdZrt2/friUlJYPOl5SU6Pbt24e0Ybhr//CHP+iJEyf0nXfe0TfeeEP379+vd999t4rIoGtFRJcsWaIbN24ceCxZsmTIdYDW1dXpd77zHX3kkUf03nvv1eXLl+uVV16Z8Pczbdo0ra6uHvSYNm1awmuLi4tHzdWN9GegOracUODBIl0PC0KFK5mAley16QpsqskHt1QEwbFe29fXp//5z3/0+PHj+ve//10ffPDBhAFz9erVCf9c8y4IATXASuA2YAVQl8RrLAiZlEllYFNNPmClKwimM7iq5tndMbfA/lpVXeI5thlYo6rD7mNjOSGTC5K9k5jsdem6NhqNsmjRIvbt20dvby/hcHjEUsB5lZgWkRZgs6ru8hyrwQlMC0Z4XTkWhIxJmbEEt3wLQqeAiKp2eo6VAqdUddg9aywIGROcvKkx7Q7FSr0BCEBVu93zNYE0zBiTMtm+dqx0lPNl8QdEZAVO8trK/RmTA7K6J+SHqraqai1ge9YYkwOyvScEODmg2BBsDEIA7733XhpaZIwZieff3agL0bI9CMUCT5nn17HENEDiehCOaQDz5s1LT8uMMcmYBhwd6YKsDkKq2iki3QzNDZW554edJwS8BswDjgNW5Dj7bcOG0Lkime8qhBOAXhvtzbI6CLl2AZWAN+BUuseHparngFdGusZkDxH5cLRbuSY7jOG7GrEHFJMLiekm4LG4Y43ucWNMjsv6npA7JGtyb7134vSCWkYZipnc0xp0A0zSUvpdZf2MaWNMfsuF4ZgxJo9ZEDLGBMqCkDEmUBaEjDGByvq7YyZ/iMhtOBNNI1y4y7kl7poaoA7nTmgZ0OmtJWUyy12dsFZVG+OOp+x7siBkMsINQAdjZVncv9wHRKRSVde5xyqBx+KraIrISZuSEZgN8QdS/T3ZcMxkSpm3LpS7ILkJWOu5pgloiXvdmrhrTIaISKynEy+l35MFIZN27v+cLQmK0B10z8eOL2XoX/pOnG6/ySDPIvFESy9S+j1ZEDJp5/aA1jH0L27sL3qnVdHMOksT5XjS8T1ZEDIZoapNCWpCLcPJEyWqlBBvSBVNkx7uMOy5YU6n/HuyxLQJhNvdX4Fzp8xkCfd78VNE0DfrCZmgbAaWxHfrPbkIE4yl8dMmEknl92RByGSciKzFmXvizTl4q2h6r02miqZJATefM9pcn5R/TzYcMxnllmTZGZ/0HGcVTZMalcAckUHb+dUBpe5/HK+p6pZUf08WhEzGuBMWB82sdf/37XaHZb6qaJrUcIdh8TPYVwJzVNVbRDCl35MNx0xGuHdcynBvx7uPGqDRkxeyKprZ57IEx1L6PVlRM5N2sW27hzndqapVnmvrcP5XjVXRtLVjAXDnAzUCsfV+z+GpaJrK78mCkDEmUDYcM8YEyoKQMSZQFoSMMYGyIGSMCZQFIWNMoCwImYwTkZUickBE1P1p68UKmAUhkzEiUiciB3AmwMXWGNVglRMLmi3bMBnhrhlrAao8daaP4kx0s1pBBcx6Qibt3OUZLUBTXOmO2Nqj+HrFpoDYjGmTdm6Pp0xVp8Ydr7HV8cZ6QiatPGuMWuPPWQAyYEHIpF9sZfWzgbbCZC0bjpm08aye744fihkTYz0hk06xfaiG27nBGAtCJq2WuT83j/WFifavEpHb3MmNdjctj9hwzKSNiCiAqspo1yZ6baLXichOnOJao+4IYXKD9YRMWrh3xSCuZnGSr60h8R7oALVYzem8YkHIpMsS9+caH6+tI0GgcUuOnszkxnwm/Ww4ZtLCHYrtUtUFo1xXilM0/TWc3k+d+/w54CjQ6tnnPLZj60735cuANZ66x7cBc3BmYMdySgtUtTGFvzWTYhaETMq5e1StxAkq3e7P13CC0sG4aw/gbDvsLXavwNT4Ho+IbHavXeA+vw1YpqpLYlsH4RRmb8QJVpXAZu97m+xjC1hNSrnBYCXOcKoMp0dSgxMccDfO28+FnE8psCDu9Z3DDLnqgPme57HdHsBZFnJQRKpwEtfdOGvTLABlOcsJmZTxDK0iqrpAVSPuHa4FwDouLFitw0kwH1DVqrhFrbUM3lQv9t6VMGSpxxycHhae7WYS5pNM9rLhmMkq7pBrp6q2xh1fgZPfWeI5dgqo8OSMSoFTfqYEmOBYT8hkmxqc4Zr3Nj84vanupHy6AAAAh0lEQVRYQjp2rlNVuz3X2e37HGRByGSbMs+Qy1v2dSA4eZ7virtuAQmGcia7WRAy2aZVRFaIyG3xs6Lj8kG7wBmmea6rxFbr5xzLCRljAmU9IWNMoCwIGWMCZUHIGBMoC0LGmEBZEDLGBMqCkDEmUBaEjDGBsiBkjAmUBSFjTKAsCBljAvX/ARhdzPlfRIZCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Lthr = np.linspace(2,40,20)\n",
    "\n",
    "FPs = np.zeros(len(Lthr))\n",
    "FPs_ste = np.zeros(len(Lthr))\n",
    "for i in range(len(Lthr)):\n",
    "    FPs[i] = np.mean(np.sum(m2lnLR_explos > Lthr[i],axis=1))\n",
    "    FPs_ste[i] = np.std(np.sum(m2lnLR_explos > Lthr[i],axis=1))/np.sqrt(len(m2lnLR_explos))\n",
    "    \n",
    "plt.close(\"all\")\n",
    "fig,axis = plt.subplots(1,1,figsize = (4,3))\n",
    "\n",
    "axis.errorbar(Lthr,FPs, yerr = FPs_ste, c = 'k', capsize = 4, fmt = 'o-',markersize=5)\n",
    "\n",
    "axis.tick_params(labelsize = 20)\n",
    "axis.spines['top'].set_linewidth(1.25)\n",
    "axis.spines['left'].set_linewidth(1.25)\n",
    "axis.spines['bottom'].set_linewidth(1.25)\n",
    "axis.spines['right'].set_linewidth(1.25)\n",
    "axis.set_ylabel(r\"False positives\",fontsize = 20)\n",
    "axis.set_xlabel(r\"$\\mathcal{L}_{thr}$\",fontsize=24)\n",
    "#fig.savefig(\"figure_FPs_explo_crossvalidation.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Explo and a subsample of Acid dataset for 10 subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "103 66 81\n",
      "0058 0228 62.78 [5 5]\n",
      "0012 0108 61.66 [0 0]\n",
      "0037 0146 39.82 [0 5]\n",
      "0041 0132 28.57 [5 0]\n",
      "0690 0452 21.73 [2 3]\n",
      "0010 0053 20.87 [0 5 5 5]\n",
      "0347 0205 15.87 [4 3]\n",
      "0057 0128 15.24 [2 3 1]\n",
      "0056 0126 14.83 [6 6 6 5]\n",
      "0075 0155 14.81 [0 4]\n",
      "0071 0146 14.14 [1 2]\n",
      "0159 0266 14.09 [3 6]\n",
      "0354 0507 13.87 [4 4]\n",
      "0056 0122 13.71 [4 0]\n",
      "0045 0104 13.54 [5 5 5 5]\n",
      "0088 0028 12.80 [3 3 3 3 3 3 3 3]\n",
      "0139 0065 11.62 [3 4]\n",
      "0060 0122 11.48 [5 4]\n",
      "0119 0052 11.40 [3 3 3 1 3 3]\n",
      "0231 0135 11.24 [3 1 3 3]\n",
      "0061 0119 10.03 [6 6 6 6 6 6 6]\n",
      "0211 0126 9.64 [3 1 3]\n",
      "0037 0082 9.57 [6 6 5 6]\n",
      "0059 0112 9.26 [3 3 3 3 3 3 3]\n",
      "0027 0061 7.49 [2 2 3 2]\n",
      "0040 0078 6.98 [5 6 6 5]\n",
      "0010 0031 6.88 [5 4 5 5]\n",
      "0330 0240 6.78 [3 3 3 1]\n",
      "0029 0062 6.52 [5 5 6 5]\n",
      "0507 0620 6.06 [6 6]\n",
      "0445 0346 6.03 [2 4]\n",
      "0165 0231 5.90 [6 6 6 6]\n",
      "0010 0029 5.86 [6 6 6 5 6 6 6 6]\n",
      "0038 0070 5.30 [6 5 6 6]\n",
      "0050 0085 5.25 [0 6]\n",
      "0024 0049 5.07 [6 5 6 5]\n",
      "0057 0091 4.53 [1 1 1 1]\n",
      "0560 0657 4.27 [3 3 3 3]\n",
      "0031 0055 4.10 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0072 0041 4.10 [3 3 2 3 3]\n",
      "0082 0120 4.09 [6 5]\n",
      "0191 0140 3.96 [3 3 1 3]\n",
      "0071 0106 3.95 [5 6 6 6]\n",
      "0281 0220 3.83 [2 3 3 3]\n",
      "0184 0235 3.50 [5 6]\n",
      "0029 0049 3.33 [5 6 5]\n",
      "1925 1786 3.04 [3 3]\n",
      "0097 0067 2.91 [3 3 3 3 3 1 3 3]\n",
      "0058 0084 2.89 [2 2 2 2]\n",
      "0026 0044 2.86 [5 5 5 6]\n",
      "0063 0041 2.58 [2 3 2 3]\n",
      "0043 0063 2.23 [3 2 3 2]\n",
      "0033 0019 2.12 [6 5 5 6]\n",
      "0186 0223 2.00 [6 6 6]\n",
      "0069 0091 1.97 [1 0]\n",
      "0101 0126 1.81 [3 3 1 3 3 3]\n",
      "0031 0019 1.75 [6 5 5 5]\n",
      "0078 0058 1.73 [2 3 2]\n",
      "0035 0050 1.59 [3 3 1 3 3]\n",
      "0095 0117 1.49 [3 0]\n",
      "0116 0094 1.38 [3 3 3 3 3 3]\n",
      "0219 0248 1.25 [2 3 3]\n",
      "0287 0256 1.21 [4 2]\n",
      "0047 0035 1.15 [3 3 1 3 3 3 3 3]\n",
      "0074 0089 1.05 [0 3]\n",
      "0074 0087 0.83 [4 6]\n",
      "0030 0022 0.82 [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0021 0026 0.61 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0014 0019 0.60 [5 6 6 6 6 6 6 6]\n",
      "0218 0231 0.43 [1 3 1]\n",
      "0024 0029 0.43 [6 6 6 6 6 6 6 5]\n",
      "0662 0684 0.42 [1 3]\n",
      "0410 0428 0.42 [2 2]\n",
      "0041 0046 0.31 [3 3 3 3 3 3 3 3 3 3]\n",
      "0064 0059 0.30 [3 3 3 3 3 3 1 3]\n",
      "0044 0049 0.27 [0 1]\n",
      "0091 0088 0.12 [3 3 3 1 3 3 3 3]\n",
      "0043 0043 0.02 [6 6 5 5]\n",
      "0084 0084 0.01 [3 1 3 1]\n",
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "103 66 81\n",
      "0011 0114 70.40 [0 0]\n",
      "0054 0195 48.12 [5 5]\n",
      "0039 0158 45.65 [5 0]\n",
      "0035 0133 35.18 [0 5]\n",
      "0199 0060 30.24 [3 1 3]\n",
      "0220 0089 23.06 [3 1 3 3]\n",
      "0650 0434 19.04 [2 3]\n",
      "0054 0134 18.81 [2 3 1]\n",
      "0069 0153 17.67 [1 2]\n",
      "0053 0126 16.89 [4 0]\n",
      "0326 0186 16.78 [4 3]\n",
      "0156 0270 16.02 [3 6]\n",
      "0334 0488 14.73 [4 4]\n",
      "0053 0119 14.08 [6 6 6 5]\n",
      "0479 0644 12.32 [6 6]\n",
      "1809 1521 12.25 [3 3]\n",
      "0025 0068 11.40 [2 2 3 2]\n",
      "0071 0137 11.39 [0 4]\n",
      "0056 0114 10.87 [5 4]\n",
      "0034 0078 9.83 [3 3 1 3 3]\n",
      "0076 0138 9.62 [6 5]\n",
      "0037 0082 9.27 [5 6 6 5]\n",
      "0042 0088 8.94 [5 5 5 5]\n",
      "0058 0109 8.70 [6 6 6 6 6 6 6]\n",
      "0024 0059 8.41 [5 5 5 6]\n",
      "0529 0657 7.25 [3 3 3 3]\n",
      "0311 0222 7.12 [3 3 3 1]\n",
      "0047 0087 6.72 [0 6]\n",
      "0028 0060 6.66 [5 5 6 5]\n",
      "0054 0095 6.26 [2 2 2 2]\n",
      "0035 0069 6.10 [6 6 5 6]\n",
      "0053 0092 5.88 [1 1 1 1]\n",
      "0176 0239 5.28 [5 6]\n",
      "0113 0068 5.18 [3 3 3 1 3 3]\n",
      "0091 0053 4.93 [3 3 3 3 3 1 3 3]\n",
      "0422 0338 4.71 [2 4]\n",
      "0068 0037 4.52 [3 3 2 3 3]\n",
      "0027 0051 4.36 [5 6 5]\n",
      "0067 0102 3.99 [5 6 6 6]\n",
      "0084 0051 3.93 [3 3 3 3 3 3 3 3]\n",
      "0618 0715 3.92 [1 3]\n",
      "0156 0205 3.78 [6 6 6 6]\n",
      "0023 0041 3.24 [6 5 6 5]\n",
      "0070 0099 2.87 [4 6]\n",
      "0184 0143 2.81 [3 3 1 3]\n",
      "0040 0060 2.43 [3 2 3 2]\n",
      "0031 0016 2.43 [6 5 5 6]\n",
      "0091 0119 2.35 [3 0]\n",
      "0054 0076 2.30 [3 3 3 3 3 3 3]\n",
      "0385 0440 2.23 [2 2]\n",
      "0110 0083 2.11 [3 3 3 3 3 3]\n",
      "0176 0212 2.01 [6 6 6]\n",
      "0019 0032 1.94 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0028 0016 1.75 [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0073 0055 1.49 [2 3 2]\n",
      "0070 0087 1.27 [0 3]\n",
      "0029 0040 1.25 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0036 0048 1.20 [6 5 6 6]\n",
      "0065 0080 1.09 [1 0]\n",
      "0023 0032 1.06 [6 6 6 6 6 6 6 5]\n",
      "0060 0048 1.02 [3 3 3 3 3 3 1 3]\n",
      "0209 0233 0.99 [2 3 3]\n",
      "0044 0034 0.93 [3 3 1 3 3 3 3 3]\n",
      "0267 0244 0.81 [2 3 3 3]\n",
      "0207 0188 0.72 [1 3 1]\n",
      "0095 0086 0.47 [3 3 1 3 3 3]\n",
      "0030 0025 0.40 [6 5 5 5]\n",
      "0041 0046 0.38 [6 6 5 5]\n",
      "0042 0037 0.32 [0 1]\n",
      "0021 0018 0.29 [5 6 5 6]\n",
      "0086 0091 0.24 [3 3 3 1 3 3 3 3]\n",
      "0079 0084 0.24 [3 1 3 1]\n",
      "0014 0016 0.21 [5 6 6 6 6 6 6 6]\n",
      "0272 0266 0.15 [4 2]\n",
      "0039 0040 0.05 [3 3 3 3 3 3 3 3 3 3]\n",
      "0060 0059 0.03 [2 3 2 3]\n",
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "103 66 81\n",
      "0011 0125 84.29 [0 0]\n",
      "0051 0224 69.26 [5 5]\n",
      "0037 0152 45.05 [5 0]\n",
      "0033 0113 27.12 [0 5]\n",
      "0615 0370 26.46 [2 3]\n",
      "0066 0154 19.41 [0 4]\n",
      "0080 0016 17.56 [3 3 3 3 3 3 3 3]\n",
      "0040 0106 17.16 [5 5 5 5]\n",
      "0050 0122 16.62 [3 3 3 3 3 3 3]\n",
      "0309 0174 16.60 [4 3]\n",
      "0051 0119 15.55 [6 6 6 5]\n",
      "0050 0118 15.25 [2 3 1]\n",
      "0298 0173 14.54 [3 3 3 1]\n",
      "0035 0091 14.32 [5 6 6 5]\n",
      "0143 0244 13.95 [3 6]\n",
      "0206 0108 13.24 [3 1 3 3]\n",
      "0033 0084 12.41 [6 6 5 6]\n",
      "0316 0451 12.26 [4 4]\n",
      "0062 0124 11.42 [1 2]\n",
      "0052 0110 11.32 [5 4]\n",
      "0049 0105 11.21 [4 0]\n",
      "0025 0067 11.15 [5 6 5]\n",
      "0024 0063 10.42 [2 2 3 2]\n",
      "0055 0109 9.89 [6 6 6 6 6 6 6]\n",
      "0103 0049 8.53 [3 3 3 1 3 3]\n",
      "0071 0127 8.37 [6 5]\n",
      "0147 0217 7.21 [6 6 6 6]\n",
      "0167 0241 7.02 [6 6 6]\n",
      "0023 0053 6.96 [5 5 5 6]\n",
      "0027 0059 6.93 [5 5 6 5]\n",
      "0122 0069 6.61 [3 4]\n",
      "0451 0563 6.52 [6 6]\n",
      "1705 1509 6.28 [3 3]\n",
      "0499 0611 6.02 [3 3 3 3]\n",
      "0044 0080 5.72 [0 6]\n",
      "0050 0087 5.68 [1 1 1 1]\n",
      "0064 0102 4.88 [5 6 6 6]\n",
      "0398 0317 4.72 [2 4]\n",
      "0064 0033 4.67 [3 3 2 3 3]\n",
      "0169 0117 4.67 [3 3 1 3]\n",
      "0087 0055 3.50 [3 3 3 3 3 1 3 3]\n",
      "0021 0040 3.50 [6 5 6 5]\n",
      "0027 0048 3.47 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0036 0060 3.29 [3 3 1 3 3]\n",
      "0069 0045 2.76 [2 3 2]\n",
      "0165 0202 2.26 [5 6]\n",
      "0051 0072 2.25 [2 2 2 2]\n",
      "0105 0078 2.16 [3 3 3 3 3 3]\n",
      "0363 0414 2.09 [2 2]\n",
      "0038 0056 2.07 [3 2 3 2]\n",
      "0085 0111 2.02 [3 0]\n",
      "0251 0212 1.91 [2 3 3 3]\n",
      "0196 0228 1.56 [1 3 1]\n",
      "0061 0078 1.45 [1 0]\n",
      "0034 0047 1.38 [6 5 6 6]\n",
      "0022 0032 1.34 [6 6 6 6 6 6 6 5]\n",
      "0255 0224 1.33 [4 2]\n",
      "0039 0052 1.32 [6 6 5 5]\n",
      "0020 0029 1.14 [5 6 5 6]\n",
      "0013 0019 1.04 [5 6 6 6 6 6 6 6]\n",
      "0018 0025 0.88 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0036 0028 0.80 [3 3 3 3 3 3 3 3 3 3]\n",
      "0057 0047 0.74 [3 3 3 3 3 3 1 3]\n",
      "0042 0033 0.73 [3 3 1 3 3 3 3 3]\n",
      "0198 0182 0.63 [2 3 3]\n",
      "0081 0071 0.58 [3 3 3 1 3 3 3 3]\n",
      "0185 0199 0.50 [3 1 3]\n",
      "0066 0074 0.50 [0 3]\n",
      "0088 0096 0.39 [3 3 1 3 3 3]\n",
      "0040 0044 0.33 [0 1]\n",
      "0018 0015 0.30 [0 3 3]\n",
      "0590 0604 0.24 [1 3]\n",
      "0026 0029 0.21 [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0065 0062 0.19 [4 6]\n",
      "0055 0052 0.17 [2 3 2 3]\n",
      "0029 0031 0.16 [6 5 5 6]\n",
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "103 66 81\n",
      "0012 0106 60.97 [0 0]\n",
      "0056 0215 58.52 [5 5]\n",
      "0035 0128 32.47 [0 5]\n",
      "0039 0134 31.44 [5 0]\n",
      "0654 0387 29.56 [2 3]\n",
      "0068 0162 21.49 [1 2]\n",
      "0057 0137 18.61 [2 3 1]\n",
      "0338 0502 16.31 [4 4]\n",
      "0485 0674 15.52 [6 6]\n",
      "0112 0038 15.43 [3 3 3 1 3 3]\n",
      "0071 0150 15.32 [0 4]\n",
      "0153 0264 15.22 [3 6]\n",
      "0043 0106 15.12 [5 5 5 5]\n",
      "0199 0098 14.64 [3 1 3]\n",
      "0053 0118 13.82 [4 0]\n",
      "0028 0078 13.49 [5 5 6 5]\n",
      "0054 0119 13.39 [6 6 6 5]\n",
      "0223 0122 12.86 [3 1 3 3]\n",
      "0332 0208 12.68 [4 3]\n",
      "0055 0117 12.51 [3 3 3 3 3 3 3]\n",
      "0057 0119 11.99 [5 4]\n",
      "0036 0085 11.43 [6 6 5 6]\n",
      "0085 0030 11.14 [3 3 3 3 3 3 3 3]\n",
      "0026 0066 10.27 [2 2 3 2]\n",
      "0077 0138 9.21 [6 5]\n",
      "0059 0110 8.72 [6 6 6 6 6 6 6]\n",
      "0317 0223 7.78 [3 3 3 1]\n",
      "0054 0095 6.23 [1 1 1 1]\n",
      "0025 0054 6.20 [5 5 5 6]\n",
      "0132 0079 6.07 [3 4]\n",
      "0023 0050 5.90 [6 5 6 5]\n",
      "0038 0071 5.70 [5 6 6 5]\n",
      "0074 0038 5.43 [2 3 2]\n",
      "0055 0092 5.39 [2 2 2 2]\n",
      "0068 0034 5.38 [3 3 2 3 3]\n",
      "0111 0067 5.20 [3 3 3 3 3 3]\n",
      "0048 0081 4.90 [0 6]\n",
      "0157 0212 4.57 [6 6 6 6]\n",
      "1827 1658 4.50 [3 3]\n",
      "0068 0105 4.49 [5 6 6 6]\n",
      "0037 0063 3.97 [6 5 6 6]\n",
      "0041 0067 3.65 [3 2 3 2]\n",
      "0027 0048 3.57 [5 6 5]\n",
      "0066 0097 3.52 [1 0]\n",
      "0428 0356 3.46 [2 4]\n",
      "0539 0617 3.09 [3 3 3 3]\n",
      "0093 0065 2.74 [3 3 3 3 3 1 3 3]\n",
      "0178 0220 2.66 [5 6]\n",
      "0030 0047 2.44 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0180 0214 1.91 [6 6 6]\n",
      "0182 0150 1.81 [3 3 1 3]\n",
      "0274 0238 1.57 [4 2]\n",
      "0014 0022 1.48 [5 6 6 6 6 6 6 6]\n",
      "0087 0068 1.47 [3 3 3 1 3 3 3 3]\n",
      "0071 0089 1.45 [0 3]\n",
      "0213 0184 1.37 [2 3 3]\n",
      "0091 0110 1.22 [3 0]\n",
      "0628 0674 1.17 [1 3]\n",
      "0045 0033 1.14 [3 3 1 3 3 3 3 3]\n",
      "0030 0021 0.96 [6 5 5 5]\n",
      "0042 0051 0.83 [6 6 5 5]\n",
      "0061 0050 0.82 [3 3 3 3 3 3 1 3]\n",
      "0389 0417 0.79 [2 2]\n",
      "0019 0026 0.72 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0070 0080 0.57 [4 6]\n",
      "0212 0198 0.47 [1 3 1]\n",
      "0028 0023 0.46 [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0023 0028 0.44 [6 6 6 6 6 6 6 5]\n",
      "0037 0042 0.41 [3 3 1 3 3]\n",
      "0022 0018 0.39 [5 6 5 6]\n",
      "0031 0027 0.34 [6 5 5 6]\n",
      "0095 0101 0.28 [3 3 1 3 3 3]\n",
      "0043 0046 0.22 [0 1]\n",
      "0079 0075 0.22 [3 1 3 1]\n",
      "0039 0036 0.16 [3 3 3 3 3 3 3 3 3 3]\n",
      "0269 0265 0.09 [2 3 3 3]\n",
      "0060 0059 0.04 [2 3 2 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "103 66 81\n",
      "0058 0223 60.09 [5 5]\n",
      "0012 0104 58.51 [0 0]\n",
      "0037 0148 41.72 [0 5]\n",
      "0041 0145 35.51 [5 0]\n",
      "0010 0057 23.43 [0 5 5 5]\n",
      "0058 0141 19.82 [3 3 3 3 3 3 3]\n",
      "0356 0539 19.08 [4 4]\n",
      "0075 0165 18.55 [0 4]\n",
      "0055 0134 18.25 [4 0]\n",
      "0348 0196 18.14 [4 3]\n",
      "0233 0114 17.53 [3 1 3 3]\n",
      "0139 0053 15.95 [3 4]\n",
      "0160 0274 15.49 [3 6]\n",
      "0061 0133 14.71 [2 3 1]\n",
      "0045 0107 14.01 [5 5 5 5]\n",
      "0057 0123 13.56 [6 6 6 5]\n",
      "0060 0125 12.68 [5 4]\n",
      "0508 0679 12.46 [6 6]\n",
      "0072 0142 12.36 [1 2]\n",
      "0010 0041 12.32 [6 6 6 5 6 6 6 6]\n",
      "0029 0074 11.88 [5 6 5]\n",
      "0038 0089 11.68 [6 6 5 6]\n",
      "0686 0524 10.19 [2 3]\n",
      "0027 0068 10.01 [2 2 3 2]\n",
      "0026 0064 9.30 [5 5 5 6]\n",
      "0081 0144 9.25 [6 5]\n",
      "0165 0246 8.52 [6 6 6 6]\n",
      "0050 0094 7.65 [0 6]\n",
      "0336 0240 7.51 [3 3 3 1]\n",
      "0040 0079 7.30 [5 6 6 5]\n",
      "0097 0050 6.85 [3 3 3 3 3 1 3 3]\n",
      "0062 0107 6.75 [6 6 6 6 6 6 6]\n",
      "0071 0033 6.37 [3 3 2 3 3]\n",
      "0117 0068 6.22 [3 3 3 1 3 3]\n",
      "0010 0030 6.16 [5 4 5 5]\n",
      "0057 0096 5.73 [1 1 1 1]\n",
      "0043 0076 5.00 [3 2 3 2]\n",
      "0038 0069 4.96 [6 5 6 6]\n",
      "1920 1742 4.74 [3 3]\n",
      "0058 0093 4.74 [2 2 2 2]\n",
      "0072 0110 4.42 [5 6 6 6]\n",
      "0097 0138 4.11 [3 0]\n",
      "0030 0052 3.62 [5 5 6 5]\n",
      "0283 0226 3.45 [2 3 3 3]\n",
      "0566 0651 3.37 [3 3 3 3]\n",
      "0408 0477 3.12 [2 2]\n",
      "0209 0163 3.10 [3 1 3]\n",
      "0068 0096 2.70 [1 0]\n",
      "0192 0151 2.67 [3 3 1 3]\n",
      "0668 0748 2.66 [1 3]\n",
      "0031 0049 2.59 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0083 0057 2.53 [3 1 3 1]\n",
      "0447 0389 2.34 [2 4]\n",
      "0117 0088 2.32 [3 3 3 3 3 3]\n",
      "0189 0228 2.26 [6 6 6]\n",
      "0014 0024 1.72 [5 6 6 6 6 6 6 6]\n",
      "0024 0036 1.66 [6 5 6 5]\n",
      "0187 0218 1.57 [5 6]\n",
      "0042 0056 1.51 [3 3 3 3 3 3 3 3 3 3]\n",
      "0024 0035 1.29 [6 6 6 6 6 6 6 5]\n",
      "0288 0256 1.28 [4 2]\n",
      "0063 0050 1.00 [2 3 2 3]\n",
      "0041 0051 0.84 [3 3 1 3 3]\n",
      "0074 0087 0.83 [4 6]\n",
      "0021 0027 0.82 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0074 0086 0.74 [0 3]\n",
      "0031 0024 0.70 [6 5 5 5]\n",
      "0221 0203 0.68 [1 3 1]\n",
      "0029 0023 0.61 [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0100 0111 0.61 [3 3 1 3 3 3]\n",
      "0047 0039 0.57 [3 3 1 3 3 3 3 3]\n",
      "0225 0213 0.35 [2 3 3]\n",
      "0033 0029 0.31 [6 5 5 6]\n",
      "0044 0048 0.25 [6 6 5 5]\n",
      "0045 0048 0.22 [0 1]\n",
      "0064 0061 0.19 [3 3 3 3 3 3 1 3]\n",
      "0091 0087 0.16 [3 3 3 1 3 3 3 3]\n",
      "0023 0021 0.11 [5 6 5 6]\n",
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "103 66 81\n",
      "0011 0111 66.53 [0 0]\n",
      "0055 0200 50.36 [5 5]\n",
      "0036 0134 35.75 [0 5]\n",
      "0039 0139 34.26 [5 0]\n",
      "0224 0086 25.65 [3 1 3 3]\n",
      "0333 0179 19.93 [4 3]\n",
      "0043 0115 19.04 [5 5 5 5]\n",
      "0054 0132 18.28 [2 3 1]\n",
      "0053 0130 17.98 [4 0]\n",
      "0155 0277 17.94 [3 6]\n",
      "0071 0157 17.75 [0 4]\n",
      "0339 0506 16.73 [4 4]\n",
      "0662 0465 15.57 [2 3]\n",
      "0038 0087 10.96 [5 6 6 5]\n",
      "0053 0109 10.85 [3 3 3 3 3 3 3]\n",
      "0054 0107 9.61 [6 6 6 5]\n",
      "0027 0066 9.42 [5 6 5]\n",
      "0086 0035 9.30 [3 3 3 3 3 3 3 3]\n",
      "0037 0080 9.15 [6 5 6 6]\n",
      "0048 0093 8.07 [0 6]\n",
      "0158 0234 7.97 [6 6 6 6]\n",
      "0065 0116 7.92 [1 2]\n",
      "0025 0058 7.52 [5 5 5 6]\n",
      "0486 0612 7.50 [6 6]\n",
      "0183 0114 7.36 [3 3 1 3]\n",
      "0036 0073 6.97 [6 6 5 6]\n",
      "0132 0077 6.70 [3 4]\n",
      "0068 0113 6.22 [5 6 6 6]\n",
      "0026 0055 6.09 [2 2 3 2]\n",
      "0319 0236 5.95 [3 3 3 1]\n",
      "0111 0064 5.93 [3 3 3 1 3 3]\n",
      "0093 0051 5.72 [3 3 3 3 3 1 3 3]\n",
      "0077 0122 5.68 [6 5]\n",
      "0068 0033 5.62 [3 3 2 3 3]\n",
      "0428 0335 5.60 [2 4]\n",
      "0275 0204 5.24 [4 2]\n",
      "0180 0244 5.23 [6 6 6]\n",
      "0059 0097 5.23 [6 6 6 6 6 6 6]\n",
      "0023 0048 5.22 [6 5 6 5]\n",
      "0030 0055 4.36 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0038 0063 3.57 [3 3 1 3 3]\n",
      "0541 0624 3.36 [3 3 3 3]\n",
      "0113 0078 3.24 [3 3 3 3 3 3]\n",
      "0057 0085 3.19 [5 4]\n",
      "0270 0217 3.09 [2 3 3 3]\n",
      "0029 0048 3.01 [5 5 6 5]\n",
      "0198 0158 2.54 [3 1 3]\n",
      "0092 0117 1.86 [3 0]\n",
      "0177 0211 1.83 [5 6]\n",
      "0391 0432 1.40 [2 2]\n",
      "0042 0055 1.34 [3 2 3 2]\n",
      "0054 0068 1.08 [1 1 1 1]\n",
      "0030 0021 1.00 [6 5 5 5]\n",
      "0079 0066 0.95 [3 1 3 1]\n",
      "0014 0020 0.94 [5 6 6 6 6 6 6 6]\n",
      "0065 0078 0.89 [1 0]\n",
      "0023 0031 0.88 [6 6 6 6 6 6 6 5]\n",
      "0212 0190 0.87 [1 3 1]\n",
      "0071 0084 0.86 [4 6]\n",
      "0632 0667 0.78 [1 3]\n",
      "0055 0066 0.76 [2 2 2 2]\n",
      "0041 0051 0.76 [6 6 5 5]\n",
      "0212 0228 0.58 [2 3 3]\n",
      "0031 0025 0.57 [6 5 5 6]\n",
      "0073 0064 0.55 [2 3 2]\n",
      "0071 0079 0.50 [0 3]\n",
      "1830 1871 0.49 [3 3]\n",
      "0022 0017 0.49 [5 6 5 6]\n",
      "0060 0052 0.48 [2 3 2 3]\n",
      "0019 0023 0.40 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0095 0103 0.38 [3 3 1 3 3 3]\n",
      "0043 0046 0.23 [0 1]\n",
      "0045 0042 0.18 [3 3 1 3 3 3 3 3]\n",
      "0061 0058 0.14 [3 3 3 3 3 3 1 3]\n",
      "0039 0040 0.06 [3 3 3 3 3 3 3 3 3 3]\n",
      "0087 0086 0.05 [3 3 3 1 3 3 3 3]\n",
      "0028 0028 0.00 [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "103 66 81\n",
      "0011 0110 65.00 [0 0]\n",
      "0056 0219 60.59 [5 5]\n",
      "0036 0146 42.79 [0 5]\n",
      "0039 0129 28.77 [5 0]\n",
      "0053 0142 23.35 [2 3 1]\n",
      "0053 0122 14.93 [4 0]\n",
      "0044 0106 14.76 [5 5 5 5]\n",
      "0072 0144 13.27 [0 4]\n",
      "0225 0124 12.84 [3 1 3 3]\n",
      "0671 0498 11.81 [2 3]\n",
      "0155 0246 10.85 [3 6]\n",
      "0342 0470 10.48 [4 4]\n",
      "0085 0034 9.45 [3 3 3 3 3 3 3 3]\n",
      "0068 0124 8.98 [1 2]\n",
      "0112 0055 8.70 [3 3 3 3 3 3]\n",
      "0026 0063 8.62 [2 2 3 2]\n",
      "0322 0227 7.65 [3 3 3 1]\n",
      "0057 0104 7.47 [5 4]\n",
      "0639 0778 7.15 [1 3]\n",
      "0027 0060 7.00 [5 6 5]\n",
      "0038 0075 6.79 [5 6 6 5]\n",
      "0059 0104 6.75 [6 6 6 6 6 6 6]\n",
      "0431 0332 6.17 [2 4]\n",
      "0055 0096 6.10 [3 3 3 3 3 3 3]\n",
      "0335 0250 6.09 [4 3]\n",
      "0036 0069 5.84 [6 6 5 6]\n",
      "0029 0058 5.58 [5 5 6 5]\n",
      "0077 0122 5.56 [6 5]\n",
      "0048 0084 5.37 [0 6]\n",
      "0071 0113 5.32 [4 6]\n",
      "0055 0091 5.16 [6 6 6 5]\n",
      "0093 0054 5.01 [3 3 3 3 3 1 3 3]\n",
      "0068 0035 4.98 [3 3 2 3 3]\n",
      "0184 0128 4.92 [3 3 1 3]\n",
      "0182 0242 4.71 [6 6 6]\n",
      "0489 0584 4.52 [6 6]\n",
      "0200 0148 4.07 [3 1 3]\n",
      "0112 0074 3.80 [3 3 3 1 3 3]\n",
      "0544 0630 3.57 [3 3 3 3]\n",
      "0030 0051 3.42 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0037 0060 3.24 [6 5 6 6]\n",
      "0025 0043 2.95 [5 5 5 6]\n",
      "0092 0125 2.92 [3 0]\n",
      "0158 0200 2.88 [6 6 6 6]\n",
      "0042 0063 2.58 [3 2 3 2]\n",
      "0069 0092 2.08 [5 6 6 6]\n",
      "0020 0032 1.98 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0023 0036 1.97 [6 5 6 5]\n",
      "0179 0212 1.79 [5 6]\n",
      "0030 0018 1.78 [6 5 5 5]\n",
      "0213 0180 1.69 [1 3 1]\n",
      "0276 0241 1.52 [4 2]\n",
      "0039 0054 1.48 [3 3 3 3 3 3 3 3 3 3]\n",
      "0066 0083 1.30 [1 0]\n",
      "0060 0045 1.28 [2 3 2 3]\n",
      "0055 0070 1.25 [2 2 2 2]\n",
      "0271 0245 0.98 [2 3 3 3]\n",
      "0080 0067 0.92 [3 1 3 1]\n",
      "0040 0050 0.89 [3 3 1 3 3]\n",
      "0055 0066 0.87 [1 1 1 1]\n",
      "0395 0421 0.72 [2 2]\n",
      "0023 0029 0.63 [6 6 6 6 6 6 6 5]\n",
      "0062 0071 0.62 [3 3 3 3 3 3 1 3]\n",
      "0043 0050 0.56 [0 1]\n",
      "0088 0078 0.50 [3 3 3 1 3 3 3 3]\n",
      "0073 0066 0.42 [2 3 2]\n",
      "0042 0048 0.42 [6 6 5 5]\n",
      "0045 0050 0.32 [3 3 1 3 3 3 3 3]\n",
      "0072 0077 0.28 [0 3]\n",
      "0028 0031 0.23 [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0014 0016 0.22 [5 6 6 6 6 6 6 6]\n",
      "0214 0208 0.17 [2 3 3]\n",
      "0022 0020 0.14 [5 6 5 6]\n",
      "1848 1860 0.12 [3 3]\n",
      "0032 0031 0.05 [6 5 5 6]\n",
      "0096 0095 0.02 [3 3 1 3 3 3]\n",
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "103 66 81\n",
      "0012 0097 51.69 [0 0]\n",
      "0058 0208 51.62 [5 5]\n",
      "0037 0137 35.04 [0 5]\n",
      "0041 0132 28.45 [5 0]\n",
      "0055 0149 24.33 [2 3 1]\n",
      "0206 0086 20.60 [3 1 3]\n",
      "0695 0483 17.03 [2 3]\n",
      "0074 0157 16.20 [0 4]\n",
      "0353 0520 16.20 [4 4]\n",
      "0057 0130 15.80 [6 6 6 5]\n",
      "0010 0046 15.45 [0 5 5 5]\n",
      "0347 0208 15.39 [4 3]\n",
      "0055 0122 13.85 [4 0]\n",
      "0159 0263 13.52 [3 6]\n",
      "0045 0102 12.48 [5 5 5 5]\n",
      "0136 0062 12.00 [3 4]\n",
      "0010 0038 10.78 [6 6 6 5 6 6 6 6]\n",
      "0088 0035 9.86 [3 3 3 3 3 3 3 3]\n",
      "0038 0083 9.83 [6 6 5 6]\n",
      "0027 0066 9.44 [2 2 3 2]\n",
      "0059 0114 9.43 [5 4]\n",
      "0057 0111 9.43 [3 3 3 3 3 3 3]\n",
      "0233 0153 7.77 [3 1 3 3]\n",
      "0061 0109 7.20 [6 6 6 6 6 6 6]\n",
      "0050 0092 6.97 [0 6]\n",
      "0116 0065 6.65 [3 3 3 1 3 3]\n",
      "0331 0246 6.11 [3 3 3 1]\n",
      "0506 0618 5.94 [6 6]\n",
      "0071 0034 5.92 [3 3 2 3 3]\n",
      "0038 0072 5.87 [6 5 6 6]\n",
      "0024 0051 5.83 [6 5 6 5]\n",
      "0028 0058 5.79 [5 6 5]\n",
      "0010 0028 5.71 [5 4 5 5]\n",
      "0074 0118 5.65 [1 2]\n",
      "0080 0126 5.55 [6 5]\n",
      "0097 0055 5.40 [3 3 3 3 3 1 3 3]\n",
      "0078 0041 5.18 [2 3 2]\n",
      "0026 0052 5.10 [5 5 5 6]\n",
      "0030 0058 5.08 [5 5 6 5]\n",
      "0071 0111 4.80 [5 6 6 6]\n",
      "0057 0093 4.80 [2 2 2 2]\n",
      "0043 0072 4.22 [3 2 3 2]\n",
      "0185 0241 4.10 [5 6]\n",
      "0040 0065 3.66 [5 6 6 5]\n",
      "0057 0087 3.63 [1 1 1 1]\n",
      "0164 0208 2.99 [6 6 6 6]\n",
      "1918 1782 2.94 [3 3]\n",
      "0031 0015 2.84 [6 5 5 5]\n",
      "0096 0127 2.57 [3 0]\n",
      "0117 0087 2.47 [3 3 3 3 3 3]\n",
      "0562 0628 2.23 [3 3 3 3]\n",
      "0082 0108 2.15 [3 1 3 1]\n",
      "0031 0047 2.05 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0446 0394 1.95 [2 4]\n",
      "0014 0023 1.35 [5 6 6 6 6 6 6 6]\n",
      "0033 0022 1.28 [6 5 5 6]\n",
      "0672 0721 1.25 [1 3]\n",
      "0282 0251 1.22 [2 3 3 3]\n",
      "0064 0050 1.20 [3 3 3 3 3 3 1 3]\n",
      "0069 0084 1.13 [1 0]\n",
      "0189 0166 1.08 [3 3 1 3]\n",
      "0409 0442 1.01 [2 2]\n",
      "0220 0197 0.94 [1 3 1]\n",
      "0287 0265 0.74 [4 2]\n",
      "0047 0038 0.71 [3 3 1 3 3 3 3 3]\n",
      "0099 0112 0.70 [3 3 1 3 3 3]\n",
      "0062 0053 0.63 [2 3 2 3]\n",
      "0074 0083 0.57 [4 6]\n",
      "0040 0047 0.51 [3 3 1 3 3]\n",
      "0091 0082 0.46 [3 3 3 1 3 3 3 3]\n",
      "0020 0025 0.46 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0030 0026 0.37 [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0041 0045 0.27 [3 3 3 3 3 3 3 3 3 3]\n",
      "0188 0195 0.21 [6 6 6]\n",
      "0074 0076 0.11 [0 3]\n",
      "0024 0025 0.06 [6 6 6 6 6 6 6 5]\n",
      "0044 0043 0.04 [6 6 5 5]\n",
      "0045 0044 0.03 [0 1]\n",
      "0222 0222 0.00 [2 3 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "103 66 81\n",
      "0011 0107 61.83 [0 0]\n",
      "0057 0207 52.54 [5 5]\n",
      "0036 0132 33.25 [0 5]\n",
      "0010 0065 30.49 [0 5 5 5]\n",
      "0040 0131 28.66 [5 0]\n",
      "0226 0085 26.30 [3 1 3 3]\n",
      "0672 0425 24.32 [2 3]\n",
      "0058 0142 20.02 [2 3 1]\n",
      "0340 0184 19.97 [4 3]\n",
      "0346 0532 19.82 [4 4]\n",
      "0073 0163 19.00 [0 4]\n",
      "0095 0022 18.40 [3 3 3 3 3 1 3 3]\n",
      "0056 0135 18.31 [3 3 3 3 3 3 3]\n",
      "0158 0266 14.44 [3 6]\n",
      "0010 0043 14.18 [6 6 6 5 6 6 6 6]\n",
      "0324 0198 13.37 [3 3 3 1]\n",
      "0055 0119 12.83 [6 6 6 5]\n",
      "0044 0101 12.37 [5 5 5 5]\n",
      "0058 0121 12.22 [5 4]\n",
      "0037 0086 11.15 [6 6 5 6]\n",
      "0497 0654 10.99 [6 6]\n",
      "0184 0281 10.35 [6 6 6]\n",
      "0039 0087 10.32 [5 6 6 5]\n",
      "0055 0108 9.72 [4 0]\n",
      "0205 0126 8.65 [3 1 3]\n",
      "0028 0065 8.51 [5 6 5]\n",
      "0059 0109 8.19 [6 6 6 6 6 6 6]\n",
      "0049 0093 7.72 [0 6]\n",
      "0135 0076 7.41 [3 4]\n",
      "0025 0058 7.35 [5 5 5 6]\n",
      "0027 0058 6.69 [2 2 3 2]\n",
      "0029 0061 6.55 [5 5 6 5]\n",
      "0038 0071 5.72 [3 3 1 3 3]\n",
      "0182 0243 4.89 [5 6]\n",
      "0116 0073 4.76 [3 3 3 1 3 3]\n",
      "0030 0056 4.67 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0070 0108 4.46 [5 6 6 6]\n",
      "0055 0087 4.23 [1 1 1 1]\n",
      "1877 1713 4.16 [3 3]\n",
      "0071 0042 3.63 [3 3 2 3 3]\n",
      "0072 0105 3.54 [1 2]\n",
      "0161 0208 3.53 [6 6 6 6]\n",
      "0400 0470 3.21 [2 2]\n",
      "0072 0102 3.08 [4 6]\n",
      "0023 0041 3.02 [6 5 6 5]\n",
      "0114 0081 3.01 [3 3 3 3 3 3]\n",
      "0080 0110 2.88 [6 5]\n",
      "0056 0082 2.75 [2 2 2 2]\n",
      "0077 0051 2.68 [2 3 2]\n",
      "0037 0058 2.64 [6 5 6 6]\n",
      "0437 0376 2.59 [2 4]\n",
      "0010 0019 2.21 [5 4 5 5]\n",
      "0081 0058 2.16 [3 1 3 1]\n",
      "0093 0121 2.15 [3 0]\n",
      "0280 0237 2.12 [4 2]\n",
      "0031 0017 2.09 [6 5 5 5]\n",
      "0043 0061 2.07 [3 2 3 2]\n",
      "0549 0602 1.59 [3 3 3 3]\n",
      "0275 0241 1.42 [2 3 3 3]\n",
      "0068 0085 1.42 [1 0]\n",
      "0014 0023 1.33 [5 6 6 6 6 6 6 6]\n",
      "0186 0161 1.23 [3 3 1 3]\n",
      "0072 0086 0.95 [0 3]\n",
      "0644 0684 0.93 [1 3]\n",
      "0024 0030 0.63 [6 6 6 6 6 6 6 5]\n",
      "0097 0086 0.60 [3 3 1 3 3 3]\n",
      "0089 0078 0.59 [3 3 3 1 3 3 3 3]\n",
      "0040 0047 0.53 [3 3 3 3 3 3 3 3 3 3]\n",
      "0063 0055 0.53 [3 3 3 3 3 3 1 3]\n",
      "0020 0025 0.52 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0045 0039 0.44 [3 3 1 3 3 3 3 3]\n",
      "0022 0026 0.32 [5 6 5 6]\n",
      "0216 0208 0.23 [1 3 1]\n",
      "0044 0047 0.20 [0 1]\n",
      "0029 0027 0.20 [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0061 0063 0.13 [2 3 2 3]\n",
      "0032 0031 0.07 [6 5 5 6]\n",
      "0043 0042 0.05 [6 6 5 5]\n",
      "0215 0214 0.04 [2 3 3]\n",
      "[ 66  67  68  69  70  71  72  73  75  76  77  80  82  84  85  89  91  92\n",
      "  93  94  95  96  98  99 100 102 104 108 109 111 112 113 114 115 117 118\n",
      " 119 121 125 130 136 138 142 145]\n",
      "103 66 81\n",
      "0011 0127 85.46 [0 0]\n",
      "0052 0184 44.57 [5 5]\n",
      "0037 0144 39.68 [5 0]\n",
      "0034 0128 34.23 [0 5]\n",
      "0144 0293 26.92 [3 6]\n",
      "0067 0163 22.33 [0 4]\n",
      "0320 0509 21.88 [4 4]\n",
      "0619 0405 19.83 [2 3]\n",
      "0040 0110 18.74 [5 5 5 5]\n",
      "0053 0131 18.73 [2 3 1]\n",
      "0052 0127 17.59 [3 3 3 3 3 3 3]\n",
      "0209 0100 16.47 [3 1 3 3]\n",
      "0314 0177 16.42 [4 3]\n",
      "0050 0120 15.83 [4 0]\n",
      "0079 0018 15.63 [3 3 3 3 3 3 3 3]\n",
      "0171 0083 12.99 [3 3 1 3]\n",
      "0124 0052 12.74 [3 4]\n",
      "0051 0109 11.86 [6 6 6 5]\n",
      "0169 0264 10.92 [6 6 6]\n",
      "0073 0138 10.81 [6 5]\n",
      "0027 0069 10.79 [5 5 6 5]\n",
      "0105 0044 10.68 [3 3 3 3 3 3]\n",
      "0055 0111 10.38 [6 6 6 6 6 6 6]\n",
      "0036 0081 10.08 [5 6 6 5]\n",
      "0087 0036 9.16 [3 3 3 3 3 1 3 3]\n",
      "0034 0077 9.12 [6 5 6 6]\n",
      "0300 0201 9.04 [3 3 3 1]\n",
      "0054 0103 8.72 [5 4]\n",
      "0023 0058 8.54 [5 5 5 6]\n",
      "0026 0060 8.00 [5 6 5]\n",
      "0034 0071 7.78 [6 6 5 6]\n",
      "0065 0026 7.44 [3 3 2 3 3]\n",
      "0459 0575 6.91 [6 6]\n",
      "0051 0093 6.83 [1 1 1 1]\n",
      "0024 0052 5.89 [2 2 3 2]\n",
      "0168 0233 5.77 [5 6]\n",
      "0148 0202 4.62 [6 6 6 6]\n",
      "0507 0602 4.51 [3 3 3 3]\n",
      "0066 0102 4.32 [1 2]\n",
      "1727 1570 4.19 [3 3]\n",
      "0039 0065 3.85 [3 2 3 2]\n",
      "0021 0041 3.71 [6 5 6 5]\n",
      "0065 0096 3.62 [5 6 6 6]\n",
      "0045 0071 3.35 [0 6]\n",
      "0188 0146 2.87 [3 1 3]\n",
      "0028 0046 2.84 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0028 0013 2.83 [6 5 5 5]\n",
      "0105 0077 2.40 [3 3 3 1 3 3]\n",
      "0062 0086 2.38 [1 0]\n",
      "0056 0037 2.21 [2 3 2 3]\n",
      "0082 0059 2.17 [3 3 3 1 3 3 3 3]\n",
      "0038 0053 1.70 [3 3 1 3 3]\n",
      "0368 0410 1.54 [2 2]\n",
      "0087 0108 1.54 [3 0]\n",
      "0259 0228 1.34 [4 2]\n",
      "0058 0045 1.09 [3 3 3 3 3 3 1 3]\n",
      "0403 0370 1.04 [2 4]\n",
      "0253 0230 0.85 [2 3 3 3]\n",
      "0067 0079 0.83 [0 3]\n",
      "0022 0029 0.78 [6 6 6 6 6 6 6 5]\n",
      "0018 0025 0.76 [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0052 0062 0.76 [2 2 2 2]\n",
      "0597 0630 0.75 [1 3]\n",
      "0027 0020 0.70 [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0089 0080 0.53 [3 3 1 3 3 3]\n",
      "0042 0049 0.49 [3 3 1 3 3 3 3 3]\n",
      "0037 0042 0.41 [3 3 3 3 3 3 3 3 3 3]\n",
      "0066 0073 0.35 [4 6]\n",
      "0071 0065 0.32 [2 3 2]\n",
      "0040 0044 0.21 [0 1]\n",
      "0039 0042 0.18 [6 6 5 5]\n",
      "0020 0018 0.17 [5 6 5 6]\n",
      "0199 0193 0.17 [1 3 1]\n",
      "0030 0031 0.08 [6 5 5 6]\n",
      "0202 0200 0.05 [2 3 3]\n",
      "0013 0013 0.02 [5 6 6 6 6 6 6 6]\n",
      "0075 0075 0.01 [3 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "niter = 10\n",
    "w_dict_combined = combine_dicts(w_dict_explo,w_dict_dbsharppH,params,model_fit)\n",
    "m2lnLR_dbsharppHs = np.zeros((niter,len(w_dict_combined)))\n",
    "emps_dbsharppHs = np.zeros((niter,len(w_dict_combined)))\n",
    "exps_dbsharppHs = np.zeros((niter,len(w_dict_combined)))\n",
    "\n",
    "for n_ in range(niter):\n",
    "    L = 0.8*len(data_dbsharppH_hmm)\n",
    "\n",
    "    length_per_traj = len(data_dbsharppH_hmm)/len(lengths_dbsharppH_hmm)\n",
    "    numtrajs = int(L/length_per_traj)\n",
    "\n",
    "    sample_lengths = np.random.choice(len(lengths_dbsharppH_hmm),numtrajs, replace=False)\n",
    "    nonsample_lengths = np.delete(np.arange(len(lengths_dbsharppH_hmm)),sample_lengths)\n",
    "\n",
    "    lengths_dbsharppH_train = lengths_dbsharppH_hmm[sample_lengths]\n",
    "    for i,l in enumerate(sample_lengths):\n",
    "        first = np.sum(lengths_dbsharppH_hmm[:l])\n",
    "        last = np.sum(lengths_dbsharppH_hmm[:l+1])\n",
    "        if i==0:\n",
    "            data_dbsharppH_train = data_dbsharppH_hmm[first:last]\n",
    "        else:\n",
    "            data_dbsharppH_train = np.concatenate((data_dbsharppH_train, data_dbsharppH_hmm[first:last]))\n",
    "            \n",
    "    lengths_explo = lengths_explo_hmm[:]\n",
    "    data_explo = data_explo_hmm[:np.sum(lengths_explo)]\n",
    "\n",
    "    Hexplo = -model_fit.score(data_explo,0)/len(data_explo) #entropy\n",
    "    Yexplo = np.exp(model_fit._compute_log_likelihood(data_explo) + Hexplo)\n",
    "\n",
    "    HdbsharppH_train =  -model_fit.score(data_dbsharppH_train,1)/len(data_dbsharppH_train) \n",
    "    YdbsharppH_train = np.exp(model_fit._compute_log_likelihood(data_dbsharppH_train) + HdbsharppH_train)\n",
    "\n",
    "    m2lnLR_dbsharppH,emps_dbsharppH,exps_dbsharppH = compare_datasets(Yexplo, lengths_explo, YdbsharppH_train, lengths_dbsharppH_train, w_dict_explo, w_dict_dbsharppH, params,model_fit)\n",
    "    \n",
    "    m2lnLR_dbsharppHs[n_] = m2lnLR_dbsharppH\n",
    "    emps_dbsharppHs[n_] = emps_dbsharppH\n",
    "    exps_dbsharppHs[n_] = exps_dbsharppH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the eight flagged sequences for L_thr = 15 (10% FP rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 [0 5] 35.74 135 36\n",
      "38 [5 0] 34.60 140 39\n",
      "51 [5 5] 55.84 210 55\n",
      "71 [3 2 3 3] 90.84 101 5\n",
      "83 [5 6 5 5] 24.96 49 6\n",
      "84 [0 5 5 5] 24.07 56 9\n",
      "86 [5 0 0 5] 46.06 63 5\n",
      "94 [0 0] 66.63 111 11\n"
     ]
    }
   ],
   "source": [
    "Lthr_acid = 15\n",
    "filtered_L = np.prod(m2lnLR_dbsharppHs > Lthr_acid, axis = 0)\n",
    "filtered_num = np.prod(emps_dbsharppHs > exps_dbsharppHs, axis = 0)\n",
    "filtered = filtered_L*filtered_num\n",
    "np.set_printoptions(precision = 2)\n",
    "filtered_indices = []\n",
    "for i in range(len(filtered)):\n",
    "    if filtered[i] == 1 and len(w_dict_combined[i]) > 1:\n",
    "        print(i,w_dict_combined[i], \"%.2f %d %d\" %(np.mean(m2lnLR_dbsharppHs,axis=0)[i], np.mean(emps_dbsharppHs,axis=0)[i],np.mean(exps_dbsharppHs,axis=0)[i]))\n",
    "        filtered_indices += [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for markovianity and then print the motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1366 0387 inf [3 3 3 3 3 3 3 3 3 3]\n",
      "0510 0050 inf [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "3234 1797 208.01 [3 3 3 3 3 3 3]\n",
      "9544 8327 42.33 [3 3 3 3]\n",
      "0311 0153 28.23 [6 6 6 6 6 6 6]\n",
      "0497 0290 27.64 [3 3 3 3 3 3 1 3]\n",
      "0495 0297 25.07 [3 3 1 3 3 3 3 3]\n",
      "1125 0824 22.72 [3 3 1 3 3 3]\n",
      "1745 1377 21.12 [3 3 1 3 3]\n",
      "2724 2289 18.50 [3 3 1 3]\n",
      "4337 3859 13.96 [3 1 3]\n",
      "0722 0554 11.12 [2 3 2]\n",
      "1428 1224 7.94 [6 6 6 6]\n",
      "0346 0254 7.28 [2 3 2 3]\n",
      "0256 0181 6.70 [1 1 1 1]\n",
      "0160 0110 5.06 [2 2 2 2]\n",
      "0115 0082 3.21 [5 5 5 5]\n",
      "39758 39308 2.72 [3]\n",
      "0099 0074 2.19 [6 5 6 5]\n",
      "0072 0054 1.72 [5 5 6 5]\n",
      "0100 0078 1.72 [5 6 5 6]\n",
      "0242 0209 1.57 [5 6 5]\n",
      "2547 2447 1.39 [6 6 6]\n",
      "23359 23128 1.13 [3 3]\n",
      "0116 0101 0.84 [6 5 5 5]\n",
      "0108 0098 0.49 [5 6 6 5]\n",
      "0273 0258 0.44 [6 6 5 6]\n",
      "0349 0338 0.28 [6 6 6 5]\n",
      "15439 15375 0.25 [1]\n",
      "0030 0028 0.18 [0 4 1]\n",
      "2266 2248 0.15 [1 2]\n",
      "0110 0106 0.15 [5 5 5 6]\n",
      "2139 2122 0.15 [4 3]\n",
      "0004 0004 0.11 [1 0 4 1]\n",
      "1063 1056 0.08 [3 0]\n",
      "1059 1053 0.07 [0 3]\n",
      "0267 0265 0.06 [6 5 6 6]\n",
      "5012 5006 0.03 [2 3]\n",
      "1218 1214 0.03 [2 4]\n",
      "7479 7475 0.01 [1 3]\n",
      "2298 2297 0.01 [2 2]\n",
      "0381 0381 0.00 [0 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "transmat_, stationary_probs_ = compute_transmat(Yexplo)\n",
    "mlnPs,emps,exps = test_for_markovianity(Yexplo,w_dict_explo,eps,p_d,transmat_, stationary_probs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n",
      "inf\n",
      "208.01\n",
      "42.33\n",
      "28.23\n",
      "27.64\n",
      "25.07\n",
      "22.72\n",
      "21.12\n",
      "18.50\n",
      "13.96\n",
      "11.12\n",
      "7.94\n",
      "7.28\n",
      "6.70\n",
      "5.06\n",
      "3.87\n",
      "3.21\n",
      "2.19\n",
      "1.79\n",
      "1.74\n",
      "1.72\n",
      "1.72\n",
      "1.66\n",
      "1.57\n",
      "1.39\n",
      "1.15\n",
      "1.13\n",
      "0.84\n",
      "0.49\n",
      "0.48\n",
      "0.44\n",
      "0.40\n",
      "0.40\n",
      "0.33\n",
      "0.29\n",
      "0.28\n",
      "0.25\n",
      "0.18\n",
      "0.17\n",
      "0.15\n",
      "0.15\n",
      "0.15\n",
      "0.14\n",
      "0.11\n",
      "0.11\n",
      "0.10\n",
      "0.08\n",
      "0.08\n",
      "0.07\n",
      "0.06\n",
      "0.05\n",
      "0.05\n",
      "0.03\n",
      "0.03\n",
      "0.01\n",
      "0.01\n",
      "0.01\n",
      "0.00\n"
     ]
    }
   ],
   "source": [
    "sorted_= np.argsort(-mlnPs)\n",
    "for w in sorted_:\n",
    "    if len(w_dict_explo[w]) > 1:\n",
    "    #if emps[w] > exps[w] and 10**(-mlnPs[w]) < 1e-3:\n",
    "        chrs = []\n",
    "        for c in w_dict_explo[w]:\n",
    "            if c == 0:\n",
    "                chrs += ['O']\n",
    "            elif c==1:\n",
    "                chrs += ['t']\n",
    "            elif c==2:\n",
    "                chrs += ['T']\n",
    "            elif c==3:\n",
    "                chrs += ['f']\n",
    "            elif c==4:\n",
    "                chrs += ['L']\n",
    "            elif c==5:\n",
    "                chrs += ['b']\n",
    "            elif c==6:\n",
    "                chrs += ['F']\n",
    "                \n",
    "            str_ = ''.join(chrs)\n",
    "        print(\"%.2f\" %mlnPs[w])\n",
    "        #print(\"%d\"%(exps[w]*len(Yexplo)))\n",
    "        #print(\"%d\"%(emps[w]*len(Yexplo)))\n",
    "        #print(str_)\n",
    "        #print(str_, \"%05d %05d %05.2f\"%(emps[w]*len(Yexplo),exps[w]*len(Yexplo),mlnPs[w]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same as above but for acid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0497 0033 inf [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0751 0093 inf [3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0334 0012 inf [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "1860 0719 278.21 [3 3 3 3 3 3 3 3]\n",
      "3266 1990 155.38 [3 3 3 3 3 3]\n",
      "0653 0294 71.86 [6 6 6 6 6 6 6]\n",
      "6533 5506 44.26 [3 3 3 3]\n",
      "0059 0004 43.87 [6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "0290 0166 17.45 [3 3 3 1 3 3 3 3]\n",
      "0285 0165 16.56 [3 3 3 3 3 1 3 3]\n",
      "2167 1821 14.89 [6 6 6 6]\n",
      "0641 0460 14.89 [3 3 3 1 3 3]\n",
      "0960 0767 10.83 [3 3 1 3 3]\n",
      "0456 0342 8.42 [2 3 2]\n",
      "0184 0123 6.54 [3 2 3 2]\n",
      "0316 0234 6.45 [5 5 5 5]\n",
      "0162 0107 6.09 [1 1 1 1]\n",
      "0087 0049 5.94 [5 6 6 6 6 6 6 6]\n",
      "0083 0047 5.67 [6 6 6 6 6 6 6 5]\n",
      "0139 0092 5.30 [2 2 2 2]\n",
      "1448 1290 4.87 [3 1 3 3]\n",
      "0056 0030 4.79 [6 6 6 5 6 6 6 6]\n",
      "0405 0330 4.18 [5 6 5]\n",
      "0148 0107 3.81 [5 5 6 5]\n",
      "0106 0072 3.68 [0 5 5 5]\n",
      "0451 0384 3.03 [3 1 3 1]\n",
      "0404 0343 2.87 [6 6 5 6]\n",
      "0142 0108 2.70 [6 5 6 5]\n",
      "0101 0073 2.62 [2 2 3 2]\n",
      "3510 3340 2.55 [6 6 6]\n",
      "26181 25818 2.42 [3]\n",
      "0143 0111 2.41 [5 6 5 6]\n",
      "0040 0025 2.34 [5 0 0 5]\n",
      "0072 0050 2.30 [5 0 5 5]\n",
      "0140 0110 2.26 [5 6 5 5]\n",
      "0890 0813 2.10 [1 3 1]\n",
      "0023 0013 1.91 [0 4 5 5]\n",
      "0065 0047 1.78 [5 5 0 5]\n",
      "0788 0724 1.72 [3 2 3 3]\n",
      "0394 0351 1.61 [6 5 6 6]\n",
      "0040 0028 1.51 [5 4 5 5]\n",
      "2093 2010 1.22 [3 6]\n",
      "0023 0015 1.21 [0 5 0 5]\n",
      "15406 15226 1.02 [3 3]\n",
      "0186 0165 0.91 [5 6 6 5]\n",
      "0448 0425 0.58 [3 3 2 3 3]\n",
      "1076 1053 0.32 [3 5]\n",
      "0784 0771 0.20 [3 0]\n",
      "0731 0723 0.12 [0 3]\n",
      "0219 0216 0.10 [5 5 5 6]\n",
      "0854 0848 0.08 [4 2]\n",
      "11494 11475 0.07 [6]\n",
      "0544 0542 0.03 [6 6 6 5]\n",
      "0364 0363 0.01 [1 0]\n",
      "1675 1674 0.01 [2 2]\n"
     ]
    }
   ],
   "source": [
    "transmat_, stationary_probs_ = compute_transmat(YdbsharppH)\n",
    "mlnPs,emps,exps = test_for_markovianity(YdbsharppH,w_dict_dbsharppH,eps,p_d,transmat_, stationary_probs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "93\n",
      "12\n",
      "719\n",
      "1990\n",
      "294\n",
      "5506\n",
      "4\n",
      "166\n",
      "165\n",
      "1821\n",
      "460\n",
      "767\n",
      "342\n",
      "123\n",
      "234\n",
      "107\n",
      "49\n",
      "47\n",
      "92\n",
      "1290\n",
      "30\n",
      "330\n",
      "107\n",
      "72\n",
      "1917\n",
      "384\n",
      "343\n",
      "108\n",
      "73\n",
      "3340\n",
      "111\n",
      "25\n",
      "50\n",
      "110\n",
      "53\n",
      "813\n",
      "13\n",
      "47\n",
      "724\n",
      "351\n",
      "28\n",
      "2010\n",
      "15\n",
      "15226\n",
      "562\n",
      "165\n",
      "1954\n",
      "6126\n",
      "425\n",
      "1934\n",
      "608\n",
      "1053\n",
      "1646\n",
      "507\n",
      "562\n",
      "568\n",
      "988\n",
      "1889\n",
      "771\n",
      "430\n",
      "723\n",
      "216\n",
      "328\n",
      "848\n",
      "441\n",
      "345\n",
      "542\n",
      "1274\n",
      "363\n",
      "651\n",
      "1674\n",
      "895\n",
      "337\n"
     ]
    }
   ],
   "source": [
    "sorted_= np.argsort(-mlnPs)\n",
    "for w in sorted_:\n",
    "    if len(w_dict_dbsharppH[w]) > 1:\n",
    "    #if emps[w] > exps[w] and 10**(-mlnPs[w]) < 1e-3:\n",
    "        chrs = []\n",
    "        for c in w_dict_dbsharppH[w]:\n",
    "            if c == 0:\n",
    "                chrs += ['O']\n",
    "            elif c==1:\n",
    "                chrs += ['t']\n",
    "            elif c==2:\n",
    "                chrs += ['T']\n",
    "            elif c==3:\n",
    "                chrs += ['f']\n",
    "            elif c==4:\n",
    "                chrs += ['L']\n",
    "            elif c==5:\n",
    "                chrs += ['b']\n",
    "            elif c==6:\n",
    "                chrs += ['F']\n",
    "                \n",
    "            str_ = ''.join(chrs)\n",
    "        #print(str_)\n",
    "        #print(\"%.2f\" %mlnPs[w])\n",
    "        #print(\"%d\"%(emps[w]*len(YdbsharppH)))\n",
    "        print(\"%d\"%(exps[w]*len(YdbsharppH)))\n",
    "        #print(str_, \"%05d %05d %05.2f\"%(emps[w]*len(YdbsharppH),exps[w]*len(YdbsharppH),mlnPs[w]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is to generate files used in the \"Zebrafish_larvae_analysis_acid_data_final\" notebook\n",
    "\n",
    "## First three cells are for acid and the four after that are for explo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_explo_hmm = np.load(\"data_explo_hmm.npy\")\n",
    "data_dbsharppH_hmm = np.load(\"data_dbsharppH_hmm.npy\")\n",
    "\n",
    "lengths_explo_hmm = np.load(\"lengths_explo_hmm.npy\")\n",
    "lengths_dbsharppH_hmm = np.load(\"lengths_dbsharppH_hmm.npy\")\n",
    "\n",
    "model_fit = GMM_model(7)\n",
    "\n",
    "means_ = np.load(\"acid_means.npy\")\n",
    "covars_ = np.load(\"acid_covars.npy\")\n",
    "weights_ = np.load(\"acid_weights.npy\")\n",
    "model_fit._read_params(means_,covars_,weights_)\n",
    "\n",
    "lengths_dbsharppH = lengths_dbsharppH_hmm\n",
    "data_dbsharppH = data_dbsharppH_hmm\n",
    "\n",
    "HdbsharppH = -model_fit.score(data_dbsharppH,1)/len(data_dbsharppH) #entropy\n",
    "YdbsharppH = np.exp(model_fit._compute_log_likelihood(data_dbsharppH))/np.exp(-HdbsharppH)\n",
    "\n",
    "w_MLs_dbsharppH,wss_dbsharppH,lss_dbsharppH = decode(YdbsharppH,lengths_dbsharppH,w_dict_combined,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_out_dbsharppH = []\n",
    "words_out_dbsharppH = []\n",
    "words_lnP_out_dbsharppH = []\n",
    "abnormal_out_dbsharppH = []\n",
    "lengths_out_dbsharppH = []\n",
    "currsum = 0\n",
    "for i,w_ML in enumerate(w_MLs_dbsharppH):\n",
    "    temp += len(w_ML)\n",
    "    chars_out_dbsharppH += w_ML\n",
    "    for k,l in enumerate(lss_dbsharppH[i]):\n",
    "        currsum += l\n",
    "        lengths_out_dbsharppH += [currsum]\n",
    "        word = wss_dbsharppH[i][k]\n",
    "        if word in filtered_indices:\n",
    "            flag = 1\n",
    "        else:\n",
    "            flag = 0\n",
    "        for j in range(l): \n",
    "            words_lnP_out_dbsharppH += [np.mean(m2lnLR_dbsharppHs,axis=0)[word]]\n",
    "            words_out_dbsharppH += [word]\n",
    "            abnormal_out_dbsharppH += [flag]\n",
    "chars_out_dbsharppH = np.array(chars_out_dbsharppH)\n",
    "words_out_dbsharppH = np.array(words_out_dbsharppH)\n",
    "words_lnP_out_dbsharppH = np.array(words_lnP_out_dbsharppH)\n",
    "abnormal_out_dbsharppH = np.array(abnormal_out_dbsharppH)\n",
    "lengths_out_dbsharppH = np.array(lengths_out_dbsharppH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"dbsharppH_data_segmented\"\n",
    "np.save(filename + \"_bouttypes\",chars_out_dbsharppH)\n",
    "np.save(filename + \"_words\",words_out_dbsharppH)\n",
    "np.save(filename + \"_words_lnP\",words_lnP_out_dbsharppH)\n",
    "np.save(filename + \"_abnormal\",abnormal_out_dbsharppH)\n",
    "np.save(filename + \"_lengths\", lengths_out_dbsharppH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_explo_hmm = np.load(\"data_explo_hmm.npy\")\n",
    "data_dbsharppH_hmm = np.load(\"data_dbsharppH_hmm.npy\")\n",
    "\n",
    "lengths_explo_hmm = np.load(\"lengths_explo_hmm.npy\")\n",
    "lengths_dbsharppH_hmm = np.load(\"lengths_dbsharppH_hmm.npy\")\n",
    "\n",
    "model_fit = GMM_model(7)\n",
    "\n",
    "means_ = np.load(\"acid_means.npy\")\n",
    "covars_ = np.load(\"acid_covars.npy\")\n",
    "weights_ = np.load(\"acid_weights.npy\")\n",
    "model_fit._read_params(means_,covars_,weights_)\n",
    "\n",
    "lengths_explo = lengths_explo_hmm\n",
    "data_explo = data_explo_hmm\n",
    "\n",
    "Hexplo = -model_fit.score(data_explo,1)/len(data_explo) #entropy\n",
    "Yexplo = np.exp(model_fit._compute_log_likelihood(data_explo))/np.exp(-Hexplo)\n",
    "\n",
    "w_MLs_explo,wss_explo,lss_explo = decode(Yexplo,lengths_explo,w_dict_explo,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368 0390 inf [3 3 3 3 3 3 3 3 3 3]\n",
      "0511 0050 inf [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "3237 1805 206.12 [3 3 3 3 3 3 3]\n",
      "9550 8341 41.71 [3 3 3 3]\n",
      "0498 0291 27.48 [3 3 3 3 3 3 1 3]\n",
      "0314 0157 27.41 [6 6 6 6 6 6 6]\n",
      "0495 0298 24.87 [3 3 1 3 3 3 3 3]\n",
      "1127 0826 22.56 [3 3 1 3 3 3]\n",
      "1748 1379 21.12 [3 3 1 3 3]\n",
      "2726 2291 18.45 [3 3 1 3]\n",
      "4336 3859 13.89 [3 1 3]\n",
      "0720 0551 11.25 [2 3 2]\n",
      "1437 1240 7.42 [6 6 6 6]\n",
      "0345 0253 7.36 [2 3 2 3]\n",
      "0253 0178 6.88 [1 1 1 1]\n",
      "0158 0107 5.37 [2 2 2 2]\n",
      "0114 0082 3.17 [5 5 5 5]\n",
      "39738 39279 2.80 [3]\n",
      "0098 0073 2.17 [6 5 6 5]\n",
      "0072 0054 1.74 [5 5 6 5]\n",
      "0099 0078 1.73 [5 6 5 6]\n",
      "0240 0208 1.58 [5 6 5]\n",
      "2558 2467 1.20 [6 6 6]\n",
      "23359 23130 1.11 [3 3]\n",
      "0115 0100 0.86 [6 5 5 5]\n",
      "0108 0098 0.49 [5 6 6 5]\n",
      "0272 0257 0.43 [6 6 5 6]\n",
      "0350 0339 0.25 [6 6 6 5]\n",
      "15442 15389 0.19 [1]\n",
      "0110 0105 0.17 [5 5 5 6]\n",
      "0030 0028 0.17 [0 4 1]\n",
      "2140 2123 0.15 [4 3]\n",
      "0004 0004 0.11 [1 0 4 1]\n",
      "2285 2273 0.09 [2 2]\n",
      "1063 1055 0.09 [3 0]\n",
      "1058 1052 0.07 [0 3]\n",
      "2275 2266 0.07 [1 2]\n",
      "0267 0264 0.06 [6 5 6 6]\n",
      "5007 4998 0.05 [2 3]\n",
      "7478 7478 0.00 [1 3]\n"
     ]
    }
   ],
   "source": [
    "transmat_, stationary_probs_ = compute_transmat(Yexplo)\n",
    "mlnPs,emps,exps = test_for_markovianity(Yexplo,w_dict_explo,eps,p_d,transmat_, stationary_probs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_out_explo = []\n",
    "words_out_explo = []\n",
    "words_lnP_out_explo = []\n",
    "lengths_out_explo = []\n",
    "currsum = 0\n",
    "for i,w_ML in enumerate(w_MLs_explo):\n",
    "    temp += len(w_ML)\n",
    "    chars_out_explo += w_ML\n",
    "    for k,l in enumerate(lss_explo[i]):\n",
    "        currsum += l\n",
    "        lengths_out_explo += [currsum]\n",
    "        word = wss_explo[i][k]\n",
    "        for j in range(l): \n",
    "            words_lnP_out_explo += [mlnPs[word]]\n",
    "            words_out_explo += [word]\n",
    "chars_out_explo = np.array(chars_out_explo)\n",
    "words_out_explo = np.array(words_out_explo)\n",
    "words_lnP_out_explo = np.array(words_lnP_out_explo)\n",
    "lengths_out_explo = np.array(lengths_out_explo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"explo_data_segmented\"\n",
    "np.save(filename + \"_bouttypes\",chars_out_explo)\n",
    "np.save(filename + \"_words\",words_out_explo)\n",
    "np.save(filename + \"_words_lnP\",words_lnP_out_explo)\n",
    "np.save(filename + \"_lengths\",lengths_out_explo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
